{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# AI Assisted Annotation \n",
    "\n",
    "Manual annotation is slow, tediousÂ and costly. Faster labeling of 3D volumes using AI annotation models accelerates this process. Clara Train offers an AIAA API that easily integrates into common medical imaging viewers\n",
    "<br><img src=\"screenShots/AIAASpeedup.png\" alt=\"Drawing\" style=\"height: 400px;\"/><br>\n",
    "\n",
    "AIAA is based on a server client model as shown below \n",
    "<br><img src=\"screenShots/AIAAClientServer.png\" alt=\"Drawing\" style=\"height: 400px;\"/><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "By the end of this notebook you will be able to:\n",
    "- Start AIAA server \n",
    "- Load a deep grow model\n",
    "- Annotate using deep grow \n",
    "- Load your model and use it for annotations  \n",
    "- Stop AIAA server\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Prerequisites\n",
    "- Nvidia GPU with 8Gb of memory   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### Resources\n",
    "It might be helpful to watch the GTC Digital 2021 talk on Clara Train SDK\n",
    "- [Clara Train 4.0 - 101 Getting Started [SE2688]](https://gtc21.event.nvidia.com/media/Clara%20Train%204.0%20-%20101%20Getting%20Started%20%5BSE2688%5D/1_0qgfrql2) \n",
    "Clara train Getting started: cover basics, BYOC, AIAA, AutoML \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Lets get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "To interact with AIAA from the command line you should use the AIAA as `AIAA -h`. \n",
    "This would show you all commands as shown below\n",
    "```\n",
    "Usage: AIAA [-h] {start,stop,status,list,load,delete} ...\n",
    "\n",
    "commands:\n",
    "  start   Start AIAA Server\n",
    "          AIAA start -h\n",
    "  stop    Stop AIAA Server\n",
    "  status  Check if AIAA Server is running\n",
    "  list    List all models loaded in AIAA\n",
    "  logs    Fetch AIAA Logs if server is running <lines>\n",
    "  load    Load a model to AIAA using one of the sources {ngc|mmar|zip|config}\n",
    "          sources:\n",
    "            ngc      Load model from NGC\n",
    "                     AIAA load <model> ngc <path> <version>\n",
    "            mmar     Load model from MMAR Folder\n",
    "                     AIAA load <model> mmar <path>\n",
    "            zip      Load model from ZIP Archive\n",
    "                     AIAA load <model> zip <path>\n",
    "            config   Load model using AIAA Config and Model saved file\n",
    "                     AIAA load <model> config <aiaa_config> <saved_model>\n",
    "            pipeline Load pipeline (as vitual model) using AIAA Config\n",
    "                     AIAA load <model> config <aiaa_config>\n",
    "  delete  Delete a model from AIAA\n",
    "          AIAA delete <model>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Before we get started let us check that we have an NVIDIA GPU available in the docker by running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug  6 11:01:55 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 106...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   68C    P2    25W /  N/A |   1163MiB /  6078MiB |      6%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# following command should show all gpus available \n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "# 1. Start AIAA server\n",
    "First lets set up AIAA path and change some permissions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIAA_ROOT is set to  /claraDevDay/AIAA/workspace/\n"
     ]
    }
   ],
   "source": [
    "AIAA_ROOT=\"/claraDevDay/AIAA/workspace/\"\n",
    "AIAA_PORT=\"5000\"\n",
    "!mkdir -p $AIAA_ROOT\n",
    "!chmod 777 $AIAA_ROOT\n",
    "print (\"AIAA_ROOT is set to \",AIAA_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "##  1.2 AIAA Server with Triton BackEnd \n",
    "Starting V4 Triton server was moved out of the clara train container. \n",
    "In order to use Triton as the AIAA backend, you should use `restartClaraTrain.sh`. \n",
    "The script uses docker-compose to start both the clara train container and triton container, \n",
    "while connected them through the docker internal network. \n",
    "\n",
    "Now lets start the AIAA server by running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIAA:: Current User: root\n",
      "AIAA:: RUNNING AIAA AS: nvidia:nvidia\n",
      "\n",
      "AIAA:: RUN FILE: /claraDevDay/AIAA/workspace/aiaa-run-config.json\n",
      "AIAA:: \n",
      "AIAA:: ENGINE:: engine=TRITON\n",
      "AIAA:: *****************************************\n",
      "AIAA:: Using TRITON Backend\n",
      "AIAA:: \n",
      "AIAA:: TRITON:: triton_ip=tritonserver\n",
      "AIAA:: TRITON:: triton_http_port=8000\n",
      "AIAA:: TRITON:: triton_grpc_port=8001\n",
      "AIAA:: TRITON:: triton_metrics_port=8002\n",
      "AIAA:: TRITON:: triton_proto=http\n",
      "AIAA:: TRITON:: triton_shmem=no\n",
      "AIAA:: TRITON:: triton_model_path=/claraDevDay/AIAA/workspace//triton_models\n",
      "AIAA:: TRITON:: triton_verbose=0\n",
      "AIAA:: TRITON:: triton_start_timeout=120\n",
      "AIAA:: TRITON:: triton_model_timeout=30\n",
      "AIAA:: \n",
      "AIAA:: Checking Triton Server is running on: tritonserver:8000\n",
      "AIAA:: Triton is up and running OK\n",
      "AIAA:: *****************************************\n",
      "AIAA:: \n",
      "AIAA:: APACHE:: LOG  DIR=/claraDevDay/AIAA/workspace//logs/0\n",
      "AIAA:: APACHE:: RUN  DIR=/claraDevDay/AIAA/workspace//apache/0/run\n",
      "AIAA:: APACHE:: LOCK DIR=/claraDevDay/AIAA/workspace//apache/0/lock\n",
      "AIAA:: \n",
      "AIAA:: ====================================================================\n",
      "AIAA:: WORKSPACE DIR=/claraDevDay/AIAA/workspace/\n",
      "AIAA:: --------------------------------------------------------------------\n",
      "AIAA:: LOG DIR=/claraDevDay/AIAA/workspace//logs/0\n",
      "AIAA:: DOWNLOAD DIR=/claraDevDay/AIAA/workspace//downloads/0\n",
      "AIAA:: MODELS DIR=/claraDevDay/AIAA/workspace//models\n",
      "AIAA:: SAMPLES DIR=/claraDevDay/AIAA/workspace/samples\n",
      "AIAA:: MMARS DIR=/claraDevDay/AIAA/workspace/mmars\n",
      "AIAA:: LIB DIR=/claraDevDay/AIAA/workspace/lib\n",
      "AIAA:: SESSIONS DIR=/claraDevDay/AIAA/workspace//sessions\n",
      "AIAA:: ====================================================================\n",
      "AIAA:: \n",
      "AIAA:: Default http server port (Inside DOCKER) is 5000.\n",
      "       Please check /etc/apache2/ports.conf for exact details.\n",
      "       Command Line Tool is also available by running 'AIAA -h' inside docker.\n",
      "\n",
      "AIAA:: +++++++++++ Starting AIAA Server in background mode (run 'stop_aiaa.sh' to stop)...\n"
     ]
    }
   ],
   "source": [
    "! AIAA start -b -w $AIAA_ROOT --engine TRITON --triton_ip tritonserver \n",
    "#! AIAA start -b -w $AIAA_ROOT --engine TRITON --triton_ip 0.0.0.0 --triton_http_port 3031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# If you just change the port or add more ports here, you will likely also\n",
      "# have to change the VirtualHost statement in\n",
      "# /etc/apache2/sites-enabled/000-default.conf\n",
      "\n",
      "Listen 5000\n",
      "\n",
      "<IfModule ssl_module>\n",
      "\tListen 5001\n",
      "</IfModule>\n",
      "\n",
      "<IfModule mod_gnutls.c>\n",
      "\tListen 5001\n",
      "</IfModule>\n",
      "\n",
      "# vim: syntax=apache ts=4 sw=4 sts=4 sr noet\n"
     ]
    }
   ],
   "source": [
    "!cat /etc/apache2/ports.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIAA:: AIAA Server stopped!!!\n"
     ]
    }
   ],
   "source": [
    "# Stop triton server\n",
    "# !AIAA stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# 2 Check on AIAA Server "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.1 using CLI\n",
    "You should check on the AIAA status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIAA Server is Up and Running [Backend Engine: TRITON]; Total Loaded Models: 3\n",
      "TRITON Server is Up and Running\n"
     ]
    }
   ],
   "source": [
    "!AIAA status   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "You can also get the last 15 lines of the logs use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-08-04 14:19:19] [INFO] (aiaa.utils.generic_utils) - Reading Model Configs from /claraDevDay/AIAA/workspace/aiaa-models-config.json\n",
      "[2021-08-04 14:19:19] [INFO] (aiaa.www.api.server_context) - Total Models Loaded = 0\n",
      "[2021-08-04 14:19:23] [INFO] (aiaa.utils.generic_utils) - Reading Model Configs from /claraDevDay/AIAA/workspace/aiaa-models-config.json\n",
      "[2021-08-04 14:19:23] [INFO] (aiaa.www.api.server_context) - Total Models Loaded = 0\n",
      "[2021-08-04 14:51:18] [INFO] (aiaa.utils.generic_utils) - Reading Model Configs from /claraDevDay/AIAA/workspace/aiaa-models-config.json\n",
      "[2021-08-04 14:51:18] [INFO] (aiaa.www.api.server_context) - Total Models Loaded = 0\n",
      "[2021-08-04 14:51:22] [INFO] (aiaa.utils.generic_utils) - Reading Model Configs from /claraDevDay/AIAA/workspace/aiaa-models-config.json\n",
      "[2021-08-04 14:51:22] [INFO] (aiaa.www.api.server_context) - Total Models Loaded = 0\n"
     ]
    }
   ],
   "source": [
    "!AIAA logs 15 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "You can then easily filter on errors as  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!AIAA logs |grep errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "To list models you can run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!AIAA list | grep name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m[]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!AIAA list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "### 2.2 Using Browser\n",
    "You can also check on the AIAA server using your browser by checking:\n",
    "- Main url `http://localhost:5000/` <br>\n",
    "- APIS to list, upload, delete models `http://localhost:5000/docs/`\n",
    "- Check logs `http://localhost:5000/logs`\n",
    "- List available models `http://localhost:5000/v1/models/` \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### 2.3 (For advanced users) Using curl commands\n",
    "You can also use curl command to do list logs \n",
    "The cell below will get the last 15 lines of the logs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-08-06 14:14:44] [INFO] (aiaa.inference.inference_utils) - PRE - Input Keys: dict_keys(['result_extension', 'result_dtype', 'result_compress', 'image_original', 'image', 'image_path', 'params', 'transform_meta'])\n",
      "[2021-08-06 14:14:48] [INFO] (aiaa.inference.inference_utils) - PRE - Transform (LoadImaged): Time: 3.1971; image: (512, 512, 111)\n",
      "[2021-08-06 14:14:48] [INFO] (aiaa.inference.inference_utils) - PRE - Transform (AddChanneld): Time: 0.0000; image: (1, 512, 512, 111)\n",
      "[2021-08-06 14:15:00] [INFO] (aiaa.inference.inference_utils) - PRE - Transform (Spacingd): Time: 12.7835; image: (1, 500, 500, 331)\n",
      "[2021-08-06 14:15:26] [INFO] (aiaa.inference.inference_utils) - PRE - Transform (ScaleIntensityRanged): Time: 25.9662; image: (1, 500, 500, 331)\n",
      "[2021-08-06 14:15:26] [INFO] (aiaa.inference.triton_inference) - Input  Shape: (1, 1, 500, 500, 331), Type: ndarray\n",
      "[2021-08-06 14:15:35] Truncated or oversized response headers received from daemon process 'AIAA_V1': /opt/nvidia/medical/aiaa/www/api_v1.wsgi\n",
      "[2021-08-06 14:15:48] [INFO] (aiaa.utils.generic_utils) - Reading Model Configs from /claraDevDay/AIAA/workspace/aiaa-models-config.json\n",
      "[2021-08-06 14:15:48] [INFO] (aiaa.utils.generic_utils) - Config Found for deepgrow3d\n",
      "[2021-08-06 14:15:48] [INFO] (aiaa.utils.generic_utils) - Config Found for spleen_seg\n",
      "[2021-08-06 14:15:48] [INFO] (aiaa.www.api.server_context) - Loading Engine for deepgrow3d\n",
      "[2021-08-06 14:15:48] [INFO] (aiaa.inference.inference_utils) - Creating Inference: aiaa.inference.TritonInference\n",
      "[2021-08-06 14:15:48] [INFO] (aiaa.www.api.server_context) - Loading Engine for spleen_seg\n",
      "[2021-08-06 14:15:48] [INFO] (aiaa.inference.inference_utils) - Creating Inference: aiaa.inference.TritonInference\n",
      "[2021-08-06 14:15:48] [INFO] (aiaa.www.api.server_context) - Total Models Loaded = 2\n"
     ]
    }
   ],
   "source": [
    "http_str=\"http://127.0.0.1:\"+AIAA_PORT+\"/logs/?lines=15\"\n",
    "!curl -X GET $http_str -H \"accept: application/json\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "To list models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"name\": \"deepgrow3d\", \"labels\": [], \"description\": \"3D DeepGrow model based on Unet\", \"version\": \"1\", \"type\": \"deepgrow\", \"deepgrow\": \"3D\"}, {\"name\": \"spleen_seg\", \"labels\": [\"spleen\"], \"description\": \"A pre-trained model for volumetric (3D) segmentation of the spleen from CT image\", \"version\": \"1\", \"type\": \"segmentation\"}]"
     ]
    }
   ],
   "source": [
    "http_str=\"http://127.0.0.1:\"+AIAA_PORT+\"/v1/models\"\n",
    "# http://18.132.85.178:5000/:\"+AIAA_PORT+\"/v1/models\"\n",
    "!curl -X GET $http_str -H \"accept: application/json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "#  3. Load models in AIAA Server. \n",
    "For this notebook we can download models from [NGC](). Models on NGC are either:\n",
    "- Annotation Models <br>\n",
    "[Deep Extreme Cut: From Extreme Points to Object Segmentation](https://arxiv.org/abs/1711.09081)\n",
    "<br><img src=\"screenShots/AIAAAnnotation.png\" alt=\"Drawing\" style=\"height: 400px;\"/><br>\n",
    "\n",
    "- Segmentation Models\n",
    "- DeepGrow MMAR \n",
    "This is an interactive model to get you started with annotation. CNN takes in single channel (image) + use single click \n",
    "for foreground or background location then produces the segmentation. it is based on [Interactive segmentation of medical images through\n",
    "fully convolution neural networks](https://arxiv.org/pdf/1903.08205.pdf)\n",
    "<br><img src=\"screenShots/AIAADeepGrow.png\" alt=\"Drawing\" style=\"height: 400px;\"/><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 3.0 Loading options\n",
    "In order to load a model to AIAA we will use the AIAA cli as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model: -h\n",
      "Usage: \u001b[32mAIAA\u001b[m load <model> {ngc|mmar|zip|config|pipeline} ...\n"
     ]
    }
   ],
   "source": [
    "! AIAA load -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "This will show you options which allows to load from ngc or a local MMAR or a local zip file, etc \n",
    "```\n",
    "root@claratrain:/claraDevDay/AIAA# AIAA load -h\n",
    "Loading Model: -h\n",
    "Usage: AIAA load <model> {ngc|mmar|zip|config|pipeline} ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 3.1 Load model trained from Getting started notebook\n",
    "In order to load model trained in the getting started notebook you can run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model: Test\n",
      "Model Saved File: /claraDevDay/GettingStarted/models/config_train_Unet/model.ts does not exist.\n"
     ]
    }
   ],
   "source": [
    "modelName=\"Test\"\n",
    "modelFolderPath=\"/claraDevDay/GettingStarted/models/config_train_Unet/model.ts\"\n",
    "configFolderPath=\"/claraDevDay/GettingStarted/config/config_aiaa.json\"\n",
    "!AIAA load $modelName config $configFolderPath $modelFolderPath \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 3.2 Using NGC CLI to download model from NGC\n",
    "You can see a [list of available pre-trained models](https://ngc.nvidia.com/containers/nvidia:clara-train-sdk) on NGC. \n",
    "You can also use `ngc registry model list nvidia/med/clara_*` to get a list of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "| Name    | Reposit | Latest  | Applica | Framewo | Precisi | Last Mo | Permiss |\n",
      "|         | ory     | Version | tion    | rk      | on      | dified  | ion     |\n",
      "+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "| clara_p | nvidia/ | 1       | Segment | Clara   | AMP     | May 20, | unlocke |\n",
      "| t_brain | med/cla |         | ation   | Train   |         | 2021    | d       |\n",
      "| _mri_se | ra_pt_b |         |         |         |         |         |         |\n",
      "| gmentat | rain_mr |         |         |         |         |         |         |\n",
      "| ion     | i_segme |         |         |         |         |         |         |\n",
      "|         | ntation |         |         |         |         |         |         |\n",
      "| clara_p | nvidia/ | 1       | Segment | Clara   | AMP     | May 20, | unlocke |\n",
      "| t_brain | med/cla |         | ation   | Train   |         | 2021    | d       |\n",
      "| _mri_se | ra_pt_b |         |         |         |         |         |         |\n",
      "| gmentat | rain_mr |         |         |         |         |         |         |\n",
      "| ion_t1c | i_segme |         |         |         |         |         |         |\n",
      "|         | ntation |         |         |         |         |         |         |\n",
      "|         | _t1c    |         |         |         |         |         |         |\n",
      "| clara_p | nvidia/ | 1       | Segment | Clara   | AMP     | May 20, | unlocke |\n",
      "| t_splee | med/cla |         | ation   | Train   |         | 2021    | d       |\n",
      "| n_ct_se | ra_pt_s |         |         |         |         |         |         |\n",
      "| gmentat | pleen_c |         |         |         |         |         |         |\n",
      "| ion     | t_segme |         |         |         |         |         |         |\n",
      "|         | ntation |         |         |         |         |         |         |\n",
      "| clara_p | nvidia/ | 1       | Annotat | Clara   | AMP     | May 20, | unlocke |\n",
      "| t_splee | med/cla |         | ion     | Train   |         | 2021    | d       |\n",
      "| n_ct_an | ra_pt_s |         |         |         |         |         |         |\n",
      "| notatio | pleen_c |         |         |         |         |         |         |\n",
      "| n       | t_annot |         |         |         |         |         |         |\n",
      "|         | ation   |         |         |         |         |         |         |\n",
      "| clara_p | nvidia/ | 1       | Segment | Clara   | AMP     | May 20, | unlocke |\n",
      "| t_pancr | med/cla |         | ation   | Train   |         | 2021    | d       |\n",
      "| eas_and | ra_pt_p |         |         |         |         |         |         |\n",
      "| _tumor_ | ancreas |         |         |         |         |         |         |\n",
      "| ct_segm | _and_tu |         |         |         |         |         |         |\n",
      "| entatio | mor_ct_ |         |         |         |         |         |         |\n",
      "| n       | segment |         |         |         |         |         |         |\n",
      "|         | ation   |         |         |         |         |         |         |\n",
      "| clara_p | nvidia/ | 1       | Annotat | Clara   | AMP     | May 21, | unlocke |\n",
      "| t_brain | med/cla |         | ion     | Train   |         | 2021    | d       |\n",
      "| _mri_an | ra_pt_b |         |         |         |         |         |         |\n",
      "| notatio | rain_mr |         |         |         |         |         |         |\n",
      "| n_t1c   | i_annot |         |         |         |         |         |         |\n",
      "|         | ation_t |         |         |         |         |         |         |\n",
      "|         | 1c      |         |         |         |         |         |         |\n",
      "| clara_p | nvidia/ | 1       | Annotat | Clara   | AMP     | May 21, | unlocke |\n",
      "| t_deepg | med/cla |         | ion     | Train   |         | 2021    | d       |\n",
      "| row_3d_ | ra_pt_d |         |         |         |         |         |         |\n",
      "| annotat | eepgrow |         |         |         |         |         |         |\n",
      "| ion     | _3d_ann |         |         |         |         |         |         |\n",
      "|         | otation |         |         |         |         |         |         |\n",
      "| clara_p | nvidia/ | 1       | Annotat | Clara   | AMP     | May 21, | unlocke |\n",
      "| t_deepg | med/cla |         | ion     | Train   |         | 2021    | d       |\n",
      "| row_2d_ | ra_pt_d |         |         |         |         |         |         |\n",
      "| annotat | eepgrow |         |         |         |         |         |         |\n",
      "| ion     | _2d_ann |         |         |         |         |         |         |\n",
      "|         | otation |         |         |         |         |         |         |\n",
      "| clara_p | nvidia/ | 1       | Segment | Clara   | AMP     | May 21, | unlocke |\n",
      "| t_covid | med/cla |         | ation   | Train   |         | 2021    | d       |\n",
      "| 19_ct_l | ra_pt_c |         |         |         |         |         |         |\n",
      "| ung_seg | ovid19_ |         |         |         |         |         |         |\n",
      "| mentati | ct_lung |         |         |         |         |         |         |\n",
      "| on      | _segmen |         |         |         |         |         |         |\n",
      "|         | tation  |         |         |         |         |         |         |\n",
      "| clara_p | nvidia/ | 1       | Segment | Clara   | AMP     | May 21, | unlocke |\n",
      "| t_covid | med/cla |         | ation   | Train   |         | 2021    | d       |\n",
      "| 19_ct_l | ra_pt_c |         |         |         |         |         |         |\n",
      "| esion_s | ovid19_ |         |         |         |         |         |         |\n",
      "| egmenta | ct_lesi |         |         |         |         |         |         |\n",
      "| tion    | on_segm |         |         |         |         |         |         |\n",
      "|         | entatio |         |         |         |         |         |         |\n",
      "|         | n       |         |         |         |         |         |         |\n",
      "| clara_p | nvidia/ | 1       | Annotat | Clara   | AMP     | May 21, | unlocke |\n",
      "| t_covid | med/cla |         | ion     | Train   |         | 2021    | d       |\n",
      "| 19_ct_l | ra_pt_c |         |         |         |         |         |         |\n",
      "| ung_ann | ovid19_ |         |         |         |         |         |         |\n",
      "| otation | ct_lung |         |         |         |         |         |         |\n",
      "|         | _annota |         |         |         |         |         |         |\n",
      "|         | tion    |         |         |         |         |         |         |\n",
      "| clara_p | nvidia/ | 1       | Detecti | Clara   | AMP     | May 21, | unlocke |\n",
      "| t_patho | med/cla |         | on      | Train   |         | 2021    | d       |\n",
      "| logy_me | ra_pt_p |         |         |         |         |         |         |\n",
      "| tastasi | atholog |         |         |         |         |         |         |\n",
      "| s_detec | y_metas |         |         |         |         |         |         |\n",
      "| tion    | tasis_d |         |         |         |         |         |         |\n",
      "|         | etectio |         |         |         |         |         |         |\n",
      "|         | n       |         |         |         |         |         |         |\n",
      "| clara_p | nvidia/ | 1       | Segment | Clara   | AMP     | Jun 02, | unlocke |\n",
      "| t_prost | med/cla |         | ation   | Train   |         | 2021    | d       |\n",
      "| ate_mri | ra_pt_p |         |         |         |         |         |         |\n",
      "| _segmen | rostate |         |         |         |         |         |         |\n",
      "| tation  | _mri_se |         |         |         |         |         |         |\n",
      "|         | gmentat |         |         |         |         |         |         |\n",
      "|         | ion     |         |         |         |         |         |         |\n",
      "| clara_p | nvidia/ | 1       | Segment | Clara   | AMP     | Jun 02, | unlocke |\n",
      "| t_liver | med/cla |         | ation   | Train   |         | 2021    | d       |\n",
      "| _and_tu | ra_pt_l |         |         |         |         |         |         |\n",
      "| mor_ct_ | iver_an |         |         |         |         |         |         |\n",
      "| segment | d_tumor |         |         |         |         |         |         |\n",
      "| ation   | _ct_seg |         |         |         |         |         |         |\n",
      "|         | mentati |         |         |         |         |         |         |\n",
      "|         | on      |         |         |         |         |         |         |\n",
      "| clara_p | nvidia/ | 1       | Segment | Clara   | AMP     | Jun 02, | unlocke |\n",
      "| t_fed_l | med/cla |         | ation   | Train   |         | 2021    | d       |\n",
      "| earning | ra_pt_f |         |         |         |         |         |         |\n",
      "| _brain_ | ed_lear |         |         |         |         |         |         |\n",
      "| tumor_m | ning_br |         |         |         |         |         |         |\n",
      "| ri_segm | ain_tum |         |         |         |         |         |         |\n",
      "| entatio | or_mri_ |         |         |         |         |         |         |\n",
      "| n       | segment |         |         |         |         |         |         |\n",
      "|         | ation   |         |         |         |         |         |         |\n",
      "| clara_p | nvidia/ | 1       | Classif | Clara   | AMP     | Jun 02, | unlocke |\n",
      "| t_covid | med/cla |         | ication | Train   |         | 2021    | d       |\n",
      "| 19_3d_c | ra_pt_c |         |         |         |         |         |         |\n",
      "| t_class | ovid19_ |         |         |         |         |         |         |\n",
      "| ificati | 3d_ct_c |         |         |         |         |         |         |\n",
      "| on      | lassifi |         |         |         |         |         |         |\n",
      "|         | cation  |         |         |         |         |         |         |\n",
      "+---------+---------+---------+---------+---------+---------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "!ngc registry model list nvidia/med/clara_pt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "| Name    | Reposit | Latest  | Applica | Framewo | Precisi | Last Mo | Permiss |\n",
      "|         | ory     | Version | tion    | rk      | on      | dified  | ion     |\n",
      "+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "| clara_t | nvidia/ | 1       | Annotat | Medical | FP32    | Mar 03, | unlocke |\n",
      "| rain_co | med/cla |         | ion     |         |         | 2021    | d       |\n",
      "| vid19_a | ra_trai |         |         |         |         |         |         |\n",
      "| nnotati | n_covid |         |         |         |         |         |         |\n",
      "| on_ct_l | 19_anno |         |         |         |         |         |         |\n",
      "| ung     | tation_ |         |         |         |         |         |         |\n",
      "|         | ct_lung |         |         |         |         |         |         |\n",
      "| clara_t | nvidia/ | 1       | Segment | Medical | FP32    | Sep 25, | unlocke |\n",
      "| rain_co | med/cla |         | ation   |         |         | 2020    | d       |\n",
      "| vid19_c | ra_trai |         |         |         |         |         |         |\n",
      "| t_lung_ | n_covid |         |         |         |         |         |         |\n",
      "| seg     | 19_ct_l |         |         |         |         |         |         |\n",
      "|         | ung_seg |         |         |         |         |         |         |\n",
      "| clara_p | nvidia/ | 1       | Segment | Clara   | AMP     | May 21, | unlocke |\n",
      "| t_covid | med/cla |         | ation   | Train   |         | 2021    | d       |\n",
      "| 19_ct_l | ra_pt_c |         |         |         |         |         |         |\n",
      "| ung_seg | ovid19_ |         |         |         |         |         |         |\n",
      "| mentati | ct_lung |         |         |         |         |         |         |\n",
      "| on      | _segmen |         |         |         |         |         |         |\n",
      "|         | tation  |         |         |         |         |         |         |\n",
      "| clara_p | nvidia/ | 1       | Annotat | Clara   | AMP     | May 21, | unlocke |\n",
      "| t_covid | med/cla |         | ion     | Train   |         | 2021    | d       |\n",
      "| 19_ct_l | ra_pt_c |         |         |         |         |         |         |\n",
      "| ung_ann | ovid19_ |         |         |         |         |         |         |\n",
      "| otation | ct_lung |         |         |         |         |         |         |\n",
      "|         | _annota |         |         |         |         |         |         |\n",
      "|         | tion    |         |         |         |         |         |         |\n",
      "+---------+---------+---------+---------+---------+---------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "# grab lung\n",
    "!ngc registry model list nvidia/med/*lung*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "| Name    | Reposit | Latest  | Applica | Framewo | Precisi | Last Mo | Permiss |\n",
      "|         | ory     | Version | tion    | rk      | on      | dified  | ion     |\n",
      "+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "| clara_p | nvidia/ | 1       | Segment | Clara   | AMP     | May 20, | unlocke |\n",
      "| t_splee | med/cla |         | ation   | Train   |         | 2021    | d       |\n",
      "| n_ct_se | ra_pt_s |         |         |         |         |         |         |\n",
      "| gmentat | pleen_c |         |         |         |         |         |         |\n",
      "| ion     | t_segme |         |         |         |         |         |         |\n",
      "|         | ntation |         |         |         |         |         |         |\n",
      "+---------+---------+---------+---------+---------+---------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "# you can then filter on the model you want so it is easier to grab the repository path \n",
    "!ngc registry model list nvidia/med/*spleen_ct_segment*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "The cell below will list the deepgrow models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "| Name    | Reposit | Latest  | Applica | Framewo | Precisi | Last Mo | Permiss |\n",
      "|         | ory     | Version | tion    | rk      | on      | dified  | ion     |\n",
      "+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "| clara_p | nvidia/ | 1       | Annotat | Clara   | AMP     | May 21, | unlocke |\n",
      "| t_deepg | med/cla |         | ion     | Train   |         | 2021    | d       |\n",
      "| row_3d_ | ra_pt_d |         |         |         |         |         |         |\n",
      "| annotat | eepgrow |         |         |         |         |         |         |\n",
      "| ion     | _3d_ann |         |         |         |         |         |         |\n",
      "|         | otation |         |         |         |         |         |         |\n",
      "| clara_p | nvidia/ | 1       | Annotat | Clara   | AMP     | May 21, | unlocke |\n",
      "| t_deepg | med/cla |         | ion     | Train   |         | 2021    | d       |\n",
      "| row_2d_ | ra_pt_d |         |         |         |         |         |         |\n",
      "| annotat | eepgrow |         |         |         |         |         |         |\n",
      "| ion     | _2d_ann |         |         |         |         |         |         |\n",
      "|         | otation |         |         |         |         |         |         |\n",
      "+---------+---------+---------+---------+---------+---------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "# you can then filter on the model you want so it is easier to grab the repository path \n",
    "!ngc registry model list nvidia/med/*clara_pt_deepgrow*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "The cell below will download the the deep grow model from NGC and load it to AIAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model: deepgrow3d\n",
      "Loading deepgrow3d from NGC: https://ngc.nvidia.com/catalog/models/nvidia:med:clara_pt_deepgrow_3d_annotation\n",
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"deepgrow3d\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"labels\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[]\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"3D DeepGrow model based on Unet\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"1\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"deepgrow\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"deepgrow\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"3D\"\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!AIAA load deepgrow3d ngc \"nvidia/med/clara_pt_deepgrow_3d_annotation\" 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "The following cell will download the spleen model and load it into the AIAA server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model: spleen_seg\n",
      "Loading spleen_seg from NGC: https://ngc.nvidia.com/catalog/models/nvidia:med:clara_pt_spleen_ct_segmentation\n",
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"spleen_seg\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"labels\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
      "    \u001b[0;32m\"spleen\"\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"A pre-trained model for volumetric (3D) segmentation of the spleen from CT image\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"1\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"segmentation\"\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!AIAA load spleen_seg ngc \"nvidia/med/clara_pt_spleen_ct_segmentation\" 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model: lung_ann\n",
      "Loading lung_ann from NGC: https://ngc.nvidia.com/catalog/models/nvidia:med:clara_pt_covid19_ct_lung_annotation\n",
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"lung_ann\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"labels\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
      "    \u001b[0;32m\"lung\"\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"A pre-trained model for volumetric (3D) segmentation of the lung from CT image using DEXtr3D\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"1\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"annotation\"\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n",
      "Loading Model: lung_seg\n",
      "Loading lung_seg from NGC: https://ngc.nvidia.com/catalog/models/nvidia:med:clara_pt_covid19_ct_lung_segmentation\n",
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"lung_seg\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"labels\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
      "    \u001b[0;32m\"lung\"\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"A pre-trained model for volumetric (3D) segmentation of the Lung from CT image\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"1\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"segmentation\"\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load lung models for annotation e segmentation (AMP precision ?)\n",
    "!AIAA load lung_ann ngc \"nvidia/med/clara_pt_covid19_ct_lung_annotation\" 1\n",
    "!AIAA load lung_seg ngc \"nvidia/med/clara_pt_covid19_ct_lung_segmentation\" 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 3.3 Manually Download model from NGC \n",
    "If you have a private registry or have early access (EA) to nvidia's developer program, \n",
    "you can manually downloaded the MMAR form NGC by clicking the ... button as shown below\n",
    "<br><img src=\"screenShots/DownloadFromNGC.png\" alt=\"Drawing\" style=\"height: 400px;\"/><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "**You should download zip file to /claraDevDay/AIAA/DownloadsFromNGC/**\n",
    "\n",
    "For example if you downloaded the covid segmentation model and named the file `CovidsegModel.zip`, \n",
    "then you can run cell below to load up the zipped file to AIAA server \n",
    "\n",
    "**Please make sure the zip file directly contains the mmar folder structure \n",
    "Error will occur if the zipped file contains a folder before the mmar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "downloadedFile=\"CovidsegModel.zip\"\n",
    "\n",
    "downloadDir=AIAA_ROOT+\"../DownloadsFromNGC/\"\n",
    "modelName=downloadedFile[:-4]\n",
    "zipmodelPath=downloadDir+downloadedFile\n",
    "!AIAA load $modelName zip $zipmodelPath\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 3.3.1 (optional) In case of error with zip file\n",
    "In case the zip files container an extra directory, you can unzip using cell below\n",
    "Zip file should have the MMAR structure. \n",
    "Cell below would unzip the MMAR then upload it to AIAA server \n",
    "```\n",
    "downloadedFile=\"deepgrow_3d.zip\"\n",
    "\n",
    "downloadDir=AIAA_ROOT+\"../DownloadsFromNGC/\"\n",
    "modelName=downloadedFile[:-4]\n",
    "modelFolderPath=downloadDir+modelName\n",
    "\n",
    "%cd $downloadDir\n",
    "!unzip $downloadedFile -d $modelName\n",
    "# then you should load the mmar to AIAA \n",
    "\n",
    "!AIAA load $modelName mmar $modelFolderPath\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 3.4 load a pipeline created from multiple models into AIAA\n",
    "AIAA now supports the concept of a pipelines which triggers multiple models one at a time.\n",
    "cell below creates a pipeline out of 3D deepgrow which gets new seed points for multiple runs of deepgrow 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model: GA_Deepgrow_Pipeline\n",
      "Loading GA_Deepgrow_Pipeline from AIAA Config: /claraDevDay/AIAA/workspace/../Deepgrow2D3D_pipeline.json\n",
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"error\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "    \u001b[0m\u001b[34;1m\"message\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
      "      \u001b[0;32m\"CLASS_INIT_ERROR\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0;32m\"Instantiation of class LargestCCd failed: module 'aiaa.transforms' has no attribute 'LargestCCd'.\"\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"AIAAException\"\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"success\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "modelName=\"GA_Deepgrow_Pipeline\"\n",
    "configFolderPath=AIAA_ROOT+\"../Deepgrow2D3D_pipeline.json\"\n",
    " \n",
    "!AIAA load $modelName pipeline $configFolderPath \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "## 3.5 Check for models loaded into AIAA\n",
    "Let us check the server and check that the model is uploaded. \n",
    "Cell below would list models loaded by the AIAA server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \"name\": \"Test\",\n",
      "    \"name\": \"deepgrow3d\",\n",
      "    \"name\": \"spleen_seg\",\n"
     ]
    }
   ],
   "source": [
    "!AIAA list |grep name  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 3.6 (Optional for advanced users) Loading models using curl commands\n",
    "For advanced users or programmers integrating with AIAA, \n",
    "They could do the above task using curl commands as:  \n",
    "\n",
    "```\n",
    "http_str=\"http://127.0.0.1:\"+AIAA_PORT+\"/admin/model/\"+modelName\n",
    "conf_str=\"config=@\"+downloadDir+modelName+\"/config/config_aiaa.json;type=application/json\"\n",
    "dataArg=\"data=@\"+downloadDir+modelName+\"/models/model.ts\"\n",
    "cmd='curl -X PUT \"'+http_str +'\" -F \"'+conf_str +'\" -F \"'+dataArg +'\"'\n",
    "```\n",
    "Command below would download from NGC and load the deep grow and spleen segmentation model to AIAA\n",
    "```\n",
    "# model name from NGC is clara_train_deepgrow_aiaa_inference_only\n",
    "http_str=\"http://127.0.0.1:\"+AIAA_PORT+\"/admin/model/clara_deepgrow\"\n",
    "!curl -X PUT $http_str \\\n",
    "     -H \"accept: application/json\" \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\"path\":\"nvidia/med/clara_train_deepgrow_aiaa_inference_only\",\"version\":\"1\"}'\n",
    "```\n",
    "```\n",
    "http_str=\"http://127.0.0.1:\"+AIAA_PORT+\"/admin/model/clara_ct_seg_spleen\"\n",
    "!curl -X PUT $http_str \\\n",
    "     -H \"accept: application/json\" \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\"path\":\"nvidia/med/clara_ct_seg_spleen\",\"version\":\"1\"}'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# 4. AIAA Clients \n",
    "\n",
    "AIAA server can connect to any client that implements the APIs found [here](https://github.com/NVIDIA/ai-assisted-annotation-client\n",
    "). \n",
    "NVIDIA has already implemented these APIs for a number of open source viewers as:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 4.1. [3D Slicer](https://www.slicer.org/)\n",
    "\n",
    "In order to use slicer you should: \n",
    "1. Install and setup slicer 3d following steps [here](https://github.com/NVIDIA/ai-assisted-annotation-client/tree/master/slicer-plugin)\n",
    "    1. Download and install recent 3D Slicer Preview Release (4.11.x) from [here](http://download.slicer.org/).\n",
    "    For Early access please use slicer 4.13 (unstable release) this is needed to enable 3d geepgrow models. \n",
    "    2. Start 3D Slicer and open the Extension manager\n",
    "    3. Install NvidiaAIAssistedAnnotation extension (in Segmentation category), wait for the installation to complete, and click Restart\n",
    "2. Install by searching for nvidia in the plugin manager\n",
    "3. Configure plugin. Add the AIAA server location and make sure the session is enabled\n",
    "   <br><img src=\"screenShots/SlicerConfig.png\" alt=\"Drawing\" style=\"height: 400px;\"/>\n",
    "4. You should load a volume and start trying the spleen and deep grow model as shown below\n",
    "     \n",
    "<br><img src=\"screenShots/Slicer.png\" alt=\"Drawing\" style=\"height: 400px;\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 4.2. [MITK](https://www.mitk.org/wiki/The_Medical_Imaging_Interaction_Toolkit_(MITK))\n",
    "MITK is another viewer that you can use with AIAA. \n",
    "You can download and install it [here](http://mitk.org/wiki/Downloads). \n",
    "Please make sure you install the release with nvidia AIAA.<br>\n",
    "_Note_: Deep grow is not enabled yet in MITK \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 4.3. [OHIF](https://docs.ohif.org/)\n",
    "We have integrated AIAA with OHIF as a plugin, This has also been adapted in to XNAT. \n",
    "Plugin code can be found as a [branch of OHIF github](https://github.com/SachidanandAlle/Viewers). \n",
    "\n",
    "For more on how to use OHIF please see [OHIF Notebook](AIAAwOHIF.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# 5. Delete Models from AIAA server  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# if you need to change the model name \n",
    "#modelName=\"Deepgrow3DV4EA\"\n",
    "!AIAA delete $modelName\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Or use the http API\n",
    "```\n",
    "http_str='\"http://127.0.0.1:'+AIAA_PORT+'/admin/model/'+modelName+'\"'\n",
    "!curl -X DELETE $http_str\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# 6. Stop AIAA server\n",
    "In order to stop the AIAA server you can run cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!AIAA stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "However, this will **not free up your gpu memory** \n",
    "since we are using **triton which is running in another container.**\n",
    "In order to release the gpu memory you would need to either stop the triton container, \n",
    "or delete the models from the triton model directory `/claraDevDay/AIAA/workspace/triton_models/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!mkdir $AIAA_ROOT/triton_models_full\n",
    "#!mv $AIAA_ROOT/triton_models_full_back/* $AIAA_ROOT/triton_models_full/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Next steps\n",
    "You should now train deepgrow yourself using \n",
    "[Train Deepgrow Notebook (2D and 3D)](AIAA/DeepGrow.ipynb) <span style=\"color:red\">(New in V4)</span>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": "<!--- SPDX-License-Identifier: Apache-2.0 -->\n"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
