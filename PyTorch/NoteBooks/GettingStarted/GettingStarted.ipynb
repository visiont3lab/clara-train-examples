{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Getting started with Clara Train SDK V4.0 PyTorch using MONAI \n",
    "Clara Train SDK simply allows researcher to train AI models using configuration files. \n",
    "It is simple to use, modular and flexible. Allowing researchers to focus on innovation, \n",
    "while leaving acceleration and performance issue for NVIDIA's engineers. \n",
    "\n",
    "Clara Train SDK consists of different modules as shown below \n",
    "<br><img src=\"screenShots/TrainBlock.png\" alt=\"Drawing\" style=\"height: 600px;\"/><br>\n",
    "   \n",
    "By the end of this notebook you will:\n",
    "1. Understand components of [Medical Model ARchive (MMAR)](https://docs.nvidia.com/clara/tlt-mi/clara-train-sdk-v4.0/nvmidl/mmar.html)\n",
    "2. Know how to configure train config json to train a CNN\n",
    "3. Train a CNN with single and multiple GPUs\n",
    "4. Fine tune a model\n",
    "5. Export a model \n",
    "6. Perform inference on testing dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Prerequisites\n",
    "- Nvidia GPU with 8Gb of memory   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Resources\n",
    "You could watch the free GTC 2021 talks covering Clara Train SDK\n",
    "- [Clara Train 4.0 - 101 Getting Started [SE2688]](https://gtc21.event.nvidia.com/media/Clara%20Train%204.0%20-%20101%20Getting%20Started%20%5BSE2688%5D/1_0qgfrql2)\n",
    "- [Clara Train 4.0 - 201 Federated Learning [SE3208]](https://gtc21.event.nvidia.com/media/Clara%20Train%204.0%20-%20201%20Federated%20Learning%20%5BSE3208%5D/1_m48t6b3y)\n",
    "- [What’s New in Clara Train 4.0 [D3114]](https://gtc21.event.nvidia.com/media/What%E2%80%99s%20New%20in%20Clara%20Train%204.0%20%5BD3114%5D/1_umvjidt2)\n",
    "- [Take Medical AI from Concept to Production using Clara Imaging [S32482]](https://gtc21.event.nvidia.com/media/Take%20Medical%20AI%20from%20Concept%20to%20Production%20using%20Clara%20Imaging%20%20%5BS32482%5D/1_6bvnvyg7)\n",
    "- [Federated Learning for Medical AI [S32530]](https://gtc21.event.nvidia.com/media/Federated%20Learning%20for%20Medical%20AI%20%5BS32530%5D/1_z26u15uk)\n",
    "- [Get Started Now on Medical Imaging AI with Clara Train on Google Cloud Platform [S32518]](https://gtc21.event.nvidia.com/media/Get%20Started%20Now%20on%20Medical%20Imaging%20AI%20with%20Clara%20Train%20on%20Google%20Cloud%20Platform%20%5BS32518%5D/1_2yjdekmi)\n",
    "- [Automate 3D Medical Imaging Segmentation with AutoML and Neural Architecture Search [S32083]](https://gtc21.event.nvidia.com/media/Automate%203D%20Medical%20Imaging%20Segmentation%20with%20AutoML%20and%20Neural%20Architecture%20Search%20%5BS32083%5D/1_r5swh2jn)\n",
    "- [A Platform for Rapid Development and Clinical Translation of ML Models for Applications in Radiology at UCSF [S31619]](https://gtc21.event.nvidia.com/media/A%20Platform%20for%20Rapid%20Development%20and%20Clinical%20Translation%20of%20ML%20Models%20for%20Applications%20in%20Radiology%20at%20UCSF%20%5BS31619%5D/1_oz8qop5a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Background\n",
    "\n",
    "Clara Train is built using a component-based architecture with using components from [MONAI](https://monai.io/) :\n",
    "MONAI’s [training workflows](https://docs.monai.io/en/latest/highlights.html#workflows) \n",
    "are based off of [PyTorch Ignite’s engine](https://pytorch.org/ignite/engine.html). \n",
    "Below is a list of different components used:\n",
    "- Training Data Pipeline\n",
    "- Validation Data Pipeline\n",
    "- [Applications](https://docs.monai.io/en/latest/apps.html)\n",
    "- [Transforms](https://docs.monai.io/en/latest/transforms.html)\n",
    "- [Data](https://docs.monai.io/en/latest/data.html)\n",
    "- [Engines](https://docs.monai.io/en/latest/engines.html)\n",
    "- [Inference methods](https://docs.monai.io/en/latest/inferers.html)\n",
    "- [Event handlers](https://docs.monai.io/en/latest/handlers.html)\n",
    "- [Network architectures](https://docs.monai.io/en/latest/networks.html)\n",
    "- [Loss functions](https://docs.monai.io/en/latest/losses.html)\n",
    "- [Optimizers](https://docs.monai.io/en/latest/optimizers.html)\n",
    "- [Metrics](https://docs.monai.io/en/latest/metrics.html)\n",
    "- [Visualizations](https://docs.monai.io/en/latest/visualize.html)\n",
    "- [Utilities](https://docs.monai.io/en/latest/utils.html)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Lets get started\n",
    "Before we get started lets check that we have an NVIDIA GPU available in the docker by running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug  4 11:33:24 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   40C    P0    42W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# following command should show all gpus available \n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Next cell defines functions that we will use throughout the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting MMAR_ROOT= /claraDevDay/GettingStarted/\n",
      "BYOC.ipynb            \u001b[0m\u001b[01;34mcommands\u001b[0m/  \u001b[01;34mcustom\u001b[0m/  \u001b[01;34meval\u001b[0m/    \u001b[01;34mresources\u001b[0m/\n",
      "GettingStarted.ipynb  \u001b[01;34mconfig\u001b[0m/    \u001b[01;34mdocs\u001b[0m/    \u001b[01;34mmodels\u001b[0m/  \u001b[01;34mscreenShots\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "MMAR_ROOT=\"/claraDevDay/GettingStarted/\"\n",
    "print (\"setting MMAR_ROOT=\",MMAR_ROOT)\n",
    "%ls $MMAR_ROOT\n",
    "\n",
    "!chmod 777 $MMAR_ROOT/commands/*\n",
    "def printFile(filePath,lnSt,lnEnd):\n",
    "    print (\"showing \",str(lnEnd-lnSt),\" lines from file \",filePath, \"starting at line\",str(lnSt))\n",
    "    !< $filePath head -n \"$lnEnd\" | tail -n +\"$lnSt\"\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Medical Model ARchive (MMAR)\n",
    "Clara Train SDK uses the [Medical Model ARchive (MMAR)](https://docs.nvidia.com/clara/tlt-mi/clara-train-sdk-v4.0/nvmidl/mmar.html). \n",
    "The MMAR defines a standard structure for organizing all artifacts produced during the model development life cycle. \n",
    "Clara Train SDK simple basic idea is to train using config file\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "**We recommend opening [config_train_Unet.json](config/config_train_Unet.json) and configuring your screen as shown below**\n",
    "<br><img src=\"screenShots/MMAR.png\" alt=\"Drawing\" style=\"height: 400px;\"/><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "You can download sample models for different problems from [NGC](https://ngc.nvidia.com/catalog/models?orderBy=modifiedDESC&pageNumber=0&query=clara&quickFilter=&filters=) <br> \n",
    "All MMAR follow the structure provided in this Notebook. if you navigate to the parent folder structure it should contain the following subdirectories\n",
    "```\n",
    "./GettingStarted \n",
    "├── commands\n",
    "├── config\n",
    "├── docs\n",
    "├── eval\n",
    "├── models\n",
    "└── resources\n",
    "```\n",
    "\n",
    "* `commands` contains a number of ready-to-run scripts for:\n",
    "    - training\n",
    "    - training with multiple GPU\n",
    "    - fine tune\n",
    "    - fine tune with multiple GPU\n",
    "    - validation\n",
    "    - validation with multiple GPU\n",
    "    - inference (testing)\n",
    "    - exporting models in TensorRT Inference Server format\n",
    "* `config` contains configuration files (in JSON format) for eac training, \n",
    "validation, and deployment for [AI-assisted annotation](https://docs.nvidia.com/clara/tlt-mi/clara-train-sdk-v4.0/aiaa/index.html) \n",
    "(_Note:_ these configuration files are used in the scripts under the `commands` folder)\n",
    "* `docs` contains local documentation for the model, but for a more complete view it is recommended you visit the NGC model page\n",
    "* `eval` is used as the output directory for model evaluation (by default)\n",
    "* `models` is where the PyTorch checkpoint model is stored, and the corresponding graph definition files.\n",
    "* `resources` currently contains the logger configuration in `log.config` file\n",
    "\n",
    "Some of the most important files you will need to understand to configure and use Clara Train SDK are\n",
    "\n",
    "1. `environment.json` which has important common parameters to set the path for \n",
    "    * `DATA_ROOT` is the root folder where the data with which we would like to train, validate, or test resides in\n",
    "    * `DATASET_JSON` expects the path to a JSON-formatted file \n",
    "    * `MMAR_CKPT_DIR` the path to the where the PyTorch checkpoint files reside\n",
    "    * `MMAR_EVAL_OUTPUT_PATH` the path to output evaluation metrics for the neural network during training, validation, and inference\n",
    "    * `PROCESSING_TASK` the type of processing task the neural net is intended to perform (currently limited to `annotation`, `segmentation`, `classification`)\n",
    "    * `PRETRAIN_WEIGHTS_FILE` (_optional_) \tdetermines the location of the pre-trained weights file; if the file does not exist and is needed, \n",
    "    the training program will download it from predefined URL from the web\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing  30  lines from file  /claraDevDay/GettingStarted//config/environment.json starting at line 0\n",
      "{\n",
      "    \"DATA_ROOT\": \"/PyTorch/NoteBooks/Data/sampleData/\",\n",
      "    \"DATASET_JSON\": \"/PyTorch/NoteBooks/Data/sampleData/dataset.json\",\n",
      "    \"PROCESSING_TASK\": \"segmentation\",\n",
      "    \"MMAR_EVAL_OUTPUT_PATH\": \"eval\",\n",
      "    \"MMAR_CKPT_DIR\": \"models\",\n",
      "    \"MMAR_CKPT\": \"models/model.pt\",\n",
      "    \"MMAR_TORCHSCRIPT\": \"models/model.ts\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "printFile(MMAR_ROOT+\"/config/environment.json\",0,30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Config.json Main Concepts \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "`config_train.json` contains all the parameters necessary to define the neural net, \n",
    "how is it trained (training hyper-parameters, loss, etc.), \n",
    "pre- and post-transformation functions necessary to modify and/or augment the data before input to the neural net, etc. \n",
    "The complete documentation on the training configuration is laid out \n",
    "[here](https://docs.nvidia.com/clara/tlt-mi/clara-train-sdk-v4.0/nvmidl/appendix/configuration.html#training-configuration).\n",
    "Configuration file defines all training related configurations. \n",
    "This is were most the researcher would spent most of his time.\n",
    "\n",
    "Lets take some time to examine each part of it.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.1. Global configurations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing  9  lines from file  /claraDevDay/GettingStarted//config/config_train_Unet.json starting at line 0\n",
      "{\n",
      "  \"epochs\": 2,\n",
      "  \"multi_gpu\": false,\n",
      "  \"amp\": true,\n",
      "  \"num_interval_per_valid\": 1,\n",
      "  \"learning_rate\": 2e-4,\n",
      "  \"tf32\": false,\n",
      "  \"determinism\": {\n",
      "    \"random_seed\": 0\n"
     ]
    }
   ],
   "source": [
    "confFile=MMAR_ROOT+\"/config/config_train_Unet.json\"\n",
    "printFile(confFile,0,9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.2. Training configurations section \n",
    "This section includes:\n",
    "1. Loss functions:\n",
    "```\n",
    "    \"loss\": {\n",
    "      \"name\": \"DiceLoss\",\n",
    "      \"args\":{\n",
    "        \"to_onehot_y\": true,\n",
    "        \"softmax\": true\n",
    "      }\n",
    "    },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "2. Optimizer\n",
    "```\n",
    "    \"optimizer\": {\n",
    "      \"name\": \"Adam\",\n",
    "      \"args\": {\n",
    "        \"lr\": \"{learning_rate}\"\n",
    "      }\n",
    "    },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "3. Learning rate scheduler\n",
    "```\n",
    "    \"lr_scheduler\": {\n",
    "      \"name\": \"StepLR\",\n",
    "      \"args\": {\n",
    "        \"step_size\": 5000,\n",
    "        \"gamma\": 0.1\n",
    "      }\n",
    "    },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "4. Network architecture\n",
    "```\n",
    "    \"model\": {\n",
    "      \"name\": \"UNet\",\n",
    "      \"args\": {\n",
    "        \"dimensions\": 3,\n",
    "        \"in_channels\": 1,\n",
    "        \"out_channels\": 2,\n",
    "        \"channels\": [16, 32, 64, 128, 256],\n",
    "        \"strides\": [2, 2, 2, 2],\n",
    "        \"num_res_units\": 2,\n",
    "        \"norm\": \"batch\"\n",
    "      }\n",
    "    },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "5. Pre-transforms\n",
    "    1. Loading transformations\n",
    "    ```\n",
    "        {\n",
    "        \"name\": \"LoadImaged\",\n",
    "        \"args\": {\n",
    "          \"keys\": [\"image\", \"label\"]\n",
    "        }\n",
    "      },\n",
    "    ```\n",
    "    2. Ensure channel first Transformation\n",
    "    ```\n",
    "      {\n",
    "        \"name\": \"EnsureChannelFirstd\",\n",
    "        \"args\": {\n",
    "          \"keys\": [\"image\", \"label\"]\n",
    "        }\n",
    "      },    \n",
    "    ```\n",
    "    2. Resample Transformation\n",
    "    ```\n",
    "      {\n",
    "        \"name\": \"Spacingd\",\n",
    "        \"args\": {\n",
    "            \"keys\": [\"image\", \"label\"],\n",
    "            \"pixdim\": [1.0, 1.0, 1.0],\n",
    "            \"mode\":[\"bilinear\", \"nearest\"]\n",
    "        }\n",
    "      },    \n",
    "    ```\n",
    "    5. Intensity Transforms\n",
    "    ```\n",
    "      {\n",
    "        \"name\": \"ScaleIntensityRanged\",\n",
    "        \"args\": {\n",
    "          \"keys\": \"image\",\n",
    "          \"a_min\": -57,\n",
    "          \"a_max\": 164,\n",
    "          \"b_min\": 0.0,\n",
    "          \"b_max\": 1.0,\n",
    "          \"clip\": true\n",
    "        }\n",
    "      },    \n",
    "    ```\n",
    "    3. Cropping transformations\n",
    "    ```\n",
    "      {\n",
    "        \"name\": \"RandCropByPosNegLabeld\",\n",
    "        \"args\": {\n",
    "          \"keys\": [\"image\", \"label\"],\n",
    "          \"label_key\": \"label\",\n",
    "          \"spatial_size\": [96, 96, 96],\n",
    "          \"pos\": 1,\n",
    "          \"neg\": 1,\n",
    "          \"num_samples\": 4,\n",
    "          \"image_key\": \"image\",\n",
    "          \"image_threshold\": 0\n",
    "        }\n",
    "      },    \n",
    "    ```\n",
    "    4. Deformable transformations\n",
    "    ```\n",
    "    ```\n",
    "    6. Augmentation Transforms\n",
    "    ```\n",
    "      {\n",
    "        \"name\": \"RandShiftIntensityd\",\n",
    "        \"args\": {\n",
    "          \"keys\": \"image\",\n",
    "          \"offsets\": 0.1,\n",
    "          \"prob\": 0.5\n",
    "        }\n",
    "      },    \n",
    "    ```\n",
    "    7. Special transforms \n",
    "    ```\n",
    "      {\n",
    "        \"name\": \"ToTensord\",\n",
    "        \"args\": {\n",
    "          \"keys\": [\"image\", \"label\"]\n",
    "        }\n",
    "      }    \n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "6. DataSet to use \n",
    "```\n",
    "    \"dataset\": {\n",
    "      \"name\": \"CacheDataset\",\n",
    "      \"data_list_file_path\": \"{DATASET_JSON}\",\n",
    "      \"data_file_base_dir\": \"{DATA_ROOT}\",\n",
    "      \"data_list_key\": \"training\",\n",
    "      \"args\": {\n",
    "        \"cache_num\": 4,\n",
    "        \"cache_rate\": 1.0,\n",
    "        \"num_workers\": 2\n",
    "      }\n",
    "    },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "7. DataLoader\n",
    "```\n",
    "    \"dataloader\": {\n",
    "      \"name\": \"DataLoader\",\n",
    "      \"args\": {\n",
    "        \"batch_size\": 2,\n",
    "        \"shuffle\": true,\n",
    "        \"num_workers\": 4\n",
    "      }\n",
    "    },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "8. inferer\n",
    "```\n",
    "    \"inferer\": {\n",
    "      \"name\": \"SimpleInferer\"\n",
    "    },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "9. Handlers\n",
    "There can be may handlers as:\n",
    "1. CheckpointLoader\n",
    "2. LrScheduleHandler\n",
    "3. ValidationHandler\n",
    "4. CheckpointSaver\n",
    "5. StatsHandler\n",
    "6. TensorBoardStatsHandler\n",
    "```\n",
    "    \"handlers\": [\n",
    "      {\n",
    "        \"name\": \"CheckpointLoader\",\n",
    "        \"disabled\": \"{dont_load_ckpt_model}\",\n",
    "        \"args\": {\n",
    "          \"load_path\": \"{MMAR_CKPT}\",\n",
    "          \"load_dict\": [\"model\"]\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"LrScheduleHandler\",\n",
    "        \"args\": {\n",
    "          \"print_lr\": true\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"ValidationHandler\",\n",
    "        \"args\": {\n",
    "          \"interval\": \"{num_interval_per_valid}\",\n",
    "          \"epoch_level\": true\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"CheckpointSaver\",\n",
    "        \"rank\": 0,\n",
    "        \"args\": {\n",
    "          \"save_dir\": \"{MMAR_CKPT_DIR}\",\n",
    "          \"save_dict\": [\"model\", \"optimizer\", \"lr_scheduler\"],\n",
    "          \"save_final\": true,\n",
    "          \"save_interval\": 5\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"StatsHandler\",\n",
    "        \"rank\": 0,\n",
    "        \"args\": {\n",
    "          \"tag_name\": \"train_loss\",\n",
    "          \"output_transform\": \"lambda x: x['loss']\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"TensorBoardStatsHandler\",\n",
    "        \"rank\": 0,\n",
    "        \"args\": {\n",
    "          \"log_dir\": \"{MMAR_CKPT_DIR}\",\n",
    "          \"tag_name\": \"train_loss\",\n",
    "          \"output_transform\": \"lambda x: x['loss']\"\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "10. Post transforms\n",
    "    1. Activations \n",
    "    2. Change to oneHot \n",
    "```\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "11. Metric\n",
    "```\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "## 3.3. Validation config \n",
    "This contains sub sections very similar to the ones in the training section including:\n",
    "1. Metric \n",
    "2. pre-transforms. Since these transforms are usually a subset from the pre-transforms in the training section, \n",
    "we can use the alias to point to these transforms by name as ` \"ref\": \"LoadNifti\"`. \n",
    "In case we use 2 transforms with the same name as `ScaleByResolution` \n",
    "we can give each an alias to refer to as `\"name\": \"ScaleByResolution#ScaleImg\"` \n",
    "then refer to it in the validation section as `ScaleImg` \n",
    "3. Image pipeline\n",
    "4. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing  36  lines from file  /claraDevDay/GettingStarted//config/config_train_Unet.json starting at line 214\n",
      "      \"args\": {\n",
      "        \"max_epochs\": \"{epochs}\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"validate\": {\n",
      "    \"pre_transforms\": [\n",
      "      {\n",
      "        \"ref\": \"LoadImaged\"\n",
      "      },\n",
      "      {\n",
      "        \"ref\": \"Spacingd\"\n",
      "      },\n",
      "      {\n",
      "        \"ref\": \"EnsureChannelFirstd\"\n",
      "      },\n",
      "      {\n",
      "        \"ref\": \"ScaleIntensityRanged\"\n",
      "      },\n",
      "      {\n",
      "        \"ref\": \"CropForegroundd\"\n",
      "      },\n",
      "      {\n",
      "        \"ref\": \"ToTensord\"\n",
      "      }\n",
      "    ],\n",
      "    \"dataset\": {\n",
      "      \"name\": \"CacheDataset\",\n",
      "      \"data_list_file_path\": \"{DATASET_JSON}\",\n",
      "      \"data_file_base_dir\": \"{DATA_ROOT}\",\n",
      "      \"data_list_key\": \"validation\",\n",
      "      \"args\": {\n",
      "        \"cache_num\": 4,\n",
      "        \"cache_rate\": 1.0,\n",
      "        \"num_workers\": 2\n",
      "      }\n",
      "    },\n"
     ]
    }
   ],
   "source": [
    "printFile(confFile,214,250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# 4. Training your first Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 4.1 Start TensorBoard \n",
    "Before we start training or while the network is training, \n",
    "you can monitor its accuracy using tensorboard in side jupyter lab as shown below \n",
    " <br><img src=\"screenShots/TensorBoard.png\" alt=\"Drawing\" style=\"height: 300px;\"/><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4.2 Training script \n",
    "We have renamed `train.sh` to `train_W_Config` as we modified it to accept parameters with the config to use\n",
    "\n",
    "Let's take a look at `train_W_Config.sh` by executing the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing  30  lines from file  /claraDevDay/GettingStarted//commands/train_W_Config.sh starting at line 0\n",
      "#!/usr/bin/env bash\n",
      "\n",
      "# SPDX-License-Identifier: Apache-2.0\n",
      "\n",
      "clear\n",
      "echo running cmd $0 $1 $2 $3\n",
      "CONFIG_FILE_NAME=$1\n",
      "GPU2USE=$2\n",
      "\n",
      "my_dir=\"$(dirname \"$0\")\"\n",
      ". $my_dir/set_env.sh\n",
      "echo \"MMAR_ROOT set to $MMAR_ROOT\"\n",
      "\n",
      "CONFIG_FILE=config/$CONFIG_FILE_NAME\n",
      "ENVIRONMENT_FILE=config/environment.json\n",
      "\n",
      "########################################### check on arguments\n",
      "if [[ -z  CONFIG_FILE_NAME  ]] ;then\n",
      "   echo Need to pass in config.json\n",
      "   exit\n",
      "fi\n",
      "if [[ -z  $GPU2USE  ]] ;then\n",
      "   GPU2USE=0\n",
      "fi\n",
      "export CUDA_VISIBLE_DEVICES=$GPU2USE\n",
      "echo ------------------------------------\n",
      "MMAR_CKPT_DIR=models/${CONFIG_FILE_NAME::-5} #remove .json from file name\n",
      "if [ -d \"$MMAR_ROOT/$MMAR_CKPT_DIR\" ]; then\n",
      "    echo deleting dir \"$MMAR_ROOT/$MMAR_CKPT_DIR\"\n",
      "    rm -r \"$MMAR_ROOT/$MMAR_CKPT_DIR\"\n"
     ]
    }
   ],
   "source": [
    "printFile(MMAR_ROOT+\"/commands/train_W_Config.sh\",0,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 4.3 Start training\n",
    "Now that we have our training configuration, to start training simply run `train.sh` as below. \n",
    "Please keep in mind that we have setup a dummy data with one file to train a dummy network fast (we only train for 2 epochs). \n",
    "Please see exercises on how to easily switch data and train a real segmentation network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2Jrunning cmd /claraDevDay/GettingStarted//commands/train_W_Config.sh config_train_Unet.json\n",
      "PYTHONPATH is :/opt/nvidia/medical:/opt/nvidia:/opt/nvidia:/claraDevDay/GettingStarted/commands/../custom\n",
      "MMAR_ROOT set to /claraDevDay/GettingStarted/commands/..\n",
      "------------------------------------\n",
      "deleting dir /claraDevDay/GettingStarted/commands/../models/config_train_Unet\n",
      "saving models to created dir /claraDevDay/GettingStarted/commands/../models/config_train_Unet\n",
      "------------------------------------\n",
      "2021-08-04 11:23:58,661 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmpeft8hq71\n",
      "2021-08-04 11:23:58,662 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmpeft8hq71/_remote_module_non_sriptable.py\n",
      "Loading dataset: 100%|████████████████████████████| 4/4 [00:11<00:00,  2.82s/it]\n",
      "Loading dataset: 100%|████████████████████████████| 4/4 [00:01<00:00,  3.38it/s]\n",
      "========== Train Config Result ===========\n",
      "Num Epochs:  2\n",
      "Use GPU:  True\n",
      "Multi GPU:  False\n",
      "Automatic Mixed Precision:  Enabled\n",
      "Determinism Training:  Enabled\n",
      "cuDNN BenchMark:  False\n",
      "CUDA Matmul Allow TF32:  False\n",
      "cuDNN Allow TF32:  False\n",
      "Model:  <class 'monai.networks.nets.unet.UNet'>\n",
      "Loss:  <class 'monai.losses.dice.DiceLoss'>\n",
      "Optimizer:  <class 'torch.optim.adam.Adam'>\n",
      "LR Scheduler:  <class 'torch.optim.lr_scheduler.StepLR'>\n",
      "Train Dataset:  <class 'monai.data.dataset.CacheDataset'>\n",
      "Train DataLoader:  <class 'monai.data.dataloader.DataLoader'>\n",
      "Train Transform #1: <class 'monai.transforms.io.dictionary.LoadImaged'>\n",
      "Train Transform #2: <class 'monai.transforms.utility.dictionary.EnsureChannelFirstd'>\n",
      "Train Transform #3: <class 'monai.transforms.spatial.dictionary.Spacingd'>\n",
      "Train Transform #4: <class 'monai.transforms.intensity.dictionary.ScaleIntensityRanged'>\n",
      "Train Transform #5: <class 'monai.transforms.croppad.dictionary.CropForegroundd'>\n",
      "Train Transform #6: <class 'monai.transforms.croppad.dictionary.RandCropByPosNegLabeld'>\n",
      "Train Transform #7: <class 'monai.transforms.intensity.dictionary.RandShiftIntensityd'>\n",
      "Train Transform #8: <class 'monai.transforms.utility.dictionary.ToTensord'>\n",
      "Validate Dataset:  <class 'monai.data.dataset.CacheDataset'>\n",
      "Validate DataLoader:  <class 'monai.data.dataloader.DataLoader'>\n",
      "Validate Transform #1: <class 'monai.transforms.io.dictionary.LoadImaged'>\n",
      "Validate Transform #2: <class 'monai.transforms.spatial.dictionary.Spacingd'>\n",
      "Validate Transform #3: <class 'monai.transforms.utility.dictionary.EnsureChannelFirstd'>\n",
      "Validate Transform #4: <class 'monai.transforms.intensity.dictionary.ScaleIntensityRanged'>\n",
      "Validate Transform #5: <class 'monai.transforms.croppad.dictionary.CropForegroundd'>\n",
      "Validate Transform #6: <class 'monai.transforms.utility.dictionary.ToTensord'>\n",
      "Train Handler #1: <class 'monai.handlers.lr_schedule_handler.LrScheduleHandler'>\n",
      "Train Handler #2: <class 'monai.handlers.validation_handler.ValidationHandler'>\n",
      "Train Handler #3: <class 'monai.handlers.checkpoint_saver.CheckpointSaver'>\n",
      "Train Handler #4: <class 'monai.handlers.stats_handler.StatsHandler'>\n",
      "Train Handler #5: <class 'monai.handlers.tensorboard_handlers.TensorBoardStatsHandler'>\n",
      "Validate Handler #1: <class 'monai.handlers.stats_handler.StatsHandler'>\n",
      "Validate Handler #2: <class 'monai.handlers.tensorboard_handlers.TensorBoardStatsHandler'>\n",
      "Validate Handler #3: <class 'monai.handlers.checkpoint_saver.CheckpointSaver'>\n",
      "Train Post Transforms #1: <class 'monai.transforms.post.dictionary.Activationsd'>\n",
      "Train Post Transforms #2: <class 'monai.transforms.post.dictionary.AsDiscreted'>\n",
      "Validate Post Transforms #1: <class 'monai.transforms.post.dictionary.Activationsd'>\n",
      "Validate Post Transforms #2: <class 'monai.transforms.post.dictionary.AsDiscreted'>\n",
      "Validate Inferer:  <class 'monai.inferers.inferer.SlidingWindowInferer'>\n",
      "Validate Key Metric:  <class 'monai.handlers.mean_dice.MeanDice'>\n",
      "Validate Additional Metric #val_acc: <class 'ignite.metrics.accuracy.Accuracy'>\n",
      "Train Inferer:  <class 'monai.inferers.inferer.SimpleInferer'>\n",
      "Train Key Metric:  <class 'ignite.metrics.accuracy.Accuracy'>\n",
      "========== End of Train Config Result ===========\n",
      "2021-08-04 11:24:14,455 - ignite.engine.engine.SupervisedTrainer - INFO - Engine run resuming from iteration 0, epoch 0 until 2 epochs\n",
      "2021-08-04 11:24:16,666 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/2, Iter: 1/4 -- train_loss: 0.5830 \n",
      "2021-08-04 11:24:16,785 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/2, Iter: 2/4 -- train_loss: 0.6381 \n",
      "2021-08-04 11:24:30,318 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/2, Iter: 3/4 -- train_loss: 0.6179 \n",
      "2021-08-04 11:24:30,429 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/2, Iter: 4/4 -- train_loss: 0.6060 \n",
      "2021-08-04 11:24:30,430 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_acc: 0.3898149419713903\n",
      "2021-08-04 11:24:30,430 - ignite.engine.engine.SupervisedTrainer - INFO - Current learning rate: 0.0002\n",
      "2021-08-04 11:24:30,431 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run resuming from iteration 0, epoch 0 until 1 epochs\n",
      "2021-08-04 11:24:32,565 - ignite.engine.engine.SupervisedEvaluator - INFO - Got new best metric of val_mean_dice: 0.04476992040872574\n",
      "2021-08-04 11:24:32,565 - ignite.engine.engine.SupervisedEvaluator - INFO - Epoch[1] Metrics -- val_acc: 0.3016 val_mean_dice: 0.0448 \n",
      "2021-08-04 11:24:32,565 - ignite.engine.engine.SupervisedEvaluator - INFO - Key metric: val_mean_dice best value: 0.04476992040872574 at epoch: 1\n",
      "2021-08-04 11:24:32,612 - ignite.engine.engine.SupervisedEvaluator - INFO - Epoch[1] Complete. Time taken: 00:00:02\n",
      "2021-08-04 11:24:32,612 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run complete. Time taken: 00:00:02\n",
      "2021-08-04 11:24:32,656 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[1] Metrics -- train_acc: 0.3898 \n",
      "2021-08-04 11:24:32,656 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_acc best value: 0.3898149419713903 at epoch: 1\n",
      "2021-08-04 11:24:32,656 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[1] Complete. Time taken: 00:00:18\n",
      "2021-08-04 11:24:41,093 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/2, Iter: 1/4 -- train_loss: 0.5945 \n",
      "2021-08-04 11:24:41,271 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/2, Iter: 2/4 -- train_loss: 0.6294 \n",
      "2021-08-04 11:24:48,710 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/2, Iter: 3/4 -- train_loss: 0.5983 \n",
      "2021-08-04 11:24:48,817 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/2, Iter: 4/4 -- train_loss: 0.6141 \n",
      "2021-08-04 11:24:48,818 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_acc: 0.4317041679664894\n",
      "2021-08-04 11:24:48,818 - ignite.engine.engine.SupervisedTrainer - INFO - Current learning rate: 0.0002\n",
      "2021-08-04 11:24:48,818 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run resuming from iteration 0, epoch 1 until 2 epochs\n",
      "2021-08-04 11:24:50,942 - ignite.engine.engine.SupervisedEvaluator - INFO - Got new best metric of val_mean_dice: 0.04933180287480354\n",
      "2021-08-04 11:24:50,942 - ignite.engine.engine.SupervisedEvaluator - INFO - Epoch[2] Metrics -- val_acc: 0.2741 val_mean_dice: 0.0493 \n",
      "2021-08-04 11:24:50,942 - ignite.engine.engine.SupervisedEvaluator - INFO - Key metric: val_mean_dice best value: 0.04933180287480354 at epoch: 2\n",
      "2021-08-04 11:24:50,998 - ignite.engine.engine.SupervisedEvaluator - INFO - Epoch[2] Complete. Time taken: 00:00:02\n",
      "2021-08-04 11:24:50,998 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run complete. Time taken: 00:00:02\n",
      "2021-08-04 11:24:51,039 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[2] Metrics -- train_acc: 0.4317 \n",
      "2021-08-04 11:24:51,039 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_acc best value: 0.4317041679664894 at epoch: 2\n",
      "2021-08-04 11:24:51,040 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[2] Complete. Time taken: 00:00:18\n",
      "2021-08-04 11:24:51,137 - ignite.engine.engine.SupervisedTrainer - INFO - Train completed, saved final checkpoint: checkpoint_final_iteration=8.pt\n",
      "2021-08-04 11:24:51,137 - ignite.engine.engine.SupervisedTrainer - INFO - Engine run complete. Time taken: 00:00:37\n",
      "2021-08-04 11:24:51,192 - medl.apps.mmar_conf - INFO - Train stats:\n",
      "{'total_epochs': 2, 'total_iterations': 4, 'best_validation_metric': 0.04933180287480354, 'best_validation_epoch': 2}\n",
      "2021-08-04 11:24:51,193 - medl.apps.mmar_conf - INFO - Total Training Time 36.73802375793457\n",
      "\n",
      "real\t0m57.606s\n",
      "user\t1m21.181s\n",
      "sys\t0m45.822s\n"
     ]
    }
   ],
   "source": [
    "! $MMAR_ROOT/commands/train_W_Config.sh config_train_Unet.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Now lets see the `models` directory, which would includes out models and the tensorboard files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 75244\n",
      "drwxr-xr-x 2 root root     4096 Aug  4 11:24 .\n",
      "drwxr-xr-x 3 1000 1000     4096 Aug  4 11:23 ..\n",
      "-rw-r--r-- 1 root root     6815 Aug  4 11:23 config_train_Unet.json\n",
      "-rw-r--r-- 1 root root     7844 Aug  4 11:24 config_train_Unet.json.log\n",
      "-rw-r--r-- 1 root root      710 Aug  4 11:24 events.out.tfevents.1628076254.0220adf0bef4.472.0\n",
      "-rw-r--r-- 1 root root 57750164 Aug  4 11:24 final_model.pt\n",
      "-rw-r--r-- 1 root root 19263078 Aug  4 11:24 model.pt\n",
      "-rw-r--r-- 1 root root      117 Aug  4 11:24 train_stats.json\n",
      "---------------------------------------\n",
      "Display content of train_stats.json\n",
      "{\"total_epochs\": 2, \"total_iterations\": 4, \"best_validation_metric\": 0.04933180287480354, \"best_validation_epoch\": 2}"
     ]
    }
   ],
   "source": [
    "! ls -la $MMAR_ROOT/models/config_train_Unet\n",
    "!echo ---------------------------------------\n",
    "!echo Display content of train_stats.json\n",
    "! cat $MMAR_ROOT/models/config_train_Unet/train_stats.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "# 5. Export Model\n",
    "\n",
    "To export the model we simply run `export.sh` which will: \n",
    "- Create ts file\n",
    "This optimized model will be used by TRITON server in AIAA and Clara Deploy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHONPATH is :/opt/nvidia/medical:/opt/nvidia:/opt/nvidia:/claraDevDay/GettingStarted/commands/../custom\n",
      "MMAR_ROOT set to /claraDevDay/GettingStarted/commands/..\n",
      "2021-08-04 11:25:03,224 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmph6s7ffqq\n",
      "2021-08-04 11:25:03,225 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmph6s7ffqq/_remote_module_non_sriptable.py\n",
      "Exported model has been tested with TorchScript, and the result looks good!\n"
     ]
    }
   ],
   "source": [
    "! $MMAR_ROOT/commands/export.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "\n",
    "lets check out what was created in the folder. \n",
    "after running cell below you should see `model.ts`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 19350033 Aug  4 11:25 /claraDevDay/GettingStarted//models/config_train_Unet/model.ts\n"
     ]
    }
   ],
   "source": [
    "!ls -la $MMAR_ROOT/models/config_train_Unet/*.ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "# 6. Validation \n",
    "Now that we have trained our model we would like to run evaluation to get some statistics and also do inference to see the resulted output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 6.1 Validate with single GPU \n",
    "To run evaluation on your validation dataset you should run `validate.sh`. \n",
    "This will run evaluation on the validation dataset and place it in the `MMAR_EVAL_OUTPUT_PATH` as configured in the [environment.json](config/environment.json) \n",
    "file (default is eval folder). \n",
    "This evaluation would give min, max, mean of the metric as specified in the config_validation file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2Jrunning cmd /claraDevDay/GettingStarted//commands/validate.sh\n",
      "PYTHONPATH is :/opt/nvidia/medical:/opt/nvidia:/opt/nvidia:/claraDevDay/GettingStarted/commands/../custom\n",
      "MMAR_ROOT set to /claraDevDay/GettingStarted/commands/..\n",
      "------------------------------------\n",
      "2021-08-04 11:25:19,799 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmpw0grr3ah\n",
      "2021-08-04 11:25:19,800 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmpw0grr3ah/_remote_module_non_sriptable.py\n",
      "loaded TorchScript model from path: /claraDevDay/GettingStarted/commands/../models/config_train_Unet/model.ts\n",
      "========== Validate Config Result ===========\n",
      "Use GPU:  True\n",
      "Multi GPU:  False\n",
      "Automatic Mixed Precision:  Enabled\n",
      "Determinism Evaluation:  Disabled\n",
      "cuDNN BenchMark:  False\n",
      "CUDA Matmul Allow TF32:  True\n",
      "cuDNN Allow TF32:  True\n",
      "Model:  <class 'torch.jit._script.RecursiveScriptModule'>\n",
      "Dataset:  <class 'monai.data.dataset.Dataset'>\n",
      "DataLoader:  <class 'monai.data.dataloader.DataLoader'>\n",
      "Validate Transform #1: <class 'monai.transforms.io.dictionary.LoadImaged'>\n",
      "Validate Transform #2: <class 'monai.transforms.utility.dictionary.EnsureChannelFirstd'>\n",
      "Validate Transform #3: <class 'monai.transforms.spatial.dictionary.Spacingd'>\n",
      "Validate Transform #4: <class 'monai.transforms.intensity.dictionary.ScaleIntensityRanged'>\n",
      "Validate Transform #5: <class 'monai.transforms.croppad.dictionary.CropForegroundd'>\n",
      "Validate Transform #6: <class 'monai.transforms.utility.dictionary.ToTensord'>\n",
      "Validate Handler #1: <class 'monai.handlers.stats_handler.StatsHandler'>\n",
      "Validate Handler #2: <class 'monai.handlers.segmentation_saver.SegmentationSaver'>\n",
      "Validate Handler #3: <class 'monai.handlers.metrics_saver.MetricsSaver'>\n",
      "Validate Post Transforms #1: <class 'monai.transforms.post.dictionary.Activationsd'>\n",
      "Validate Post Transforms #2: <class 'monai.transforms.post.dictionary.AsDiscreted'>\n",
      "Validate Inferer:  <class 'monai.inferers.inferer.SlidingWindowInferer'>\n",
      "Validate Key Metric:  <class 'monai.handlers.mean_dice.MeanDice'>\n",
      "Validate Additional Metric #val_acc: <class 'ignite.metrics.accuracy.Accuracy'>\n",
      "========== End of Validate Config Result ===========\n",
      "2021-08-04 11:25:23,198 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run resuming from iteration 0, epoch 0 until 1 epochs\n",
      "file written: /claraDevDay/GettingStarted/eval/spleen_8/spleen_8_seg.nii.gz.\n",
      "2021-08-04 11:25:34,835 - ignite.engine.engine.SupervisedEvaluator - INFO - saved all the model outputs into files.\n",
      "file written: /claraDevDay/GettingStarted/eval/spleen_8/spleen_8_seg.nii.gz.\n",
      "2021-08-04 11:25:37,022 - ignite.engine.engine.SupervisedEvaluator - INFO - saved all the model outputs into files.\n",
      "file written: /claraDevDay/GettingStarted/eval/spleen_8/spleen_8_seg.nii.gz.\n",
      "2021-08-04 11:25:39,105 - ignite.engine.engine.SupervisedEvaluator - INFO - saved all the model outputs into files.\n",
      "file written: /claraDevDay/GettingStarted/eval/spleen_8/spleen_8_seg.nii.gz.\n",
      "2021-08-04 11:25:41,185 - ignite.engine.engine.SupervisedEvaluator - INFO - saved all the model outputs into files.\n",
      "2021-08-04 11:25:41,186 - ignite.engine.engine.SupervisedEvaluator - INFO - Got new best metric of val_mean_dice: 0.06937741488218307\n",
      "2021-08-04 11:25:41,187 - ignite.engine.engine.SupervisedEvaluator - INFO - Epoch[1] Metrics -- val_acc: 0.4644 val_mean_dice: 0.0694 \n",
      "2021-08-04 11:25:41,187 - ignite.engine.engine.SupervisedEvaluator - INFO - Key metric: val_mean_dice best value: 0.06937741488218307 at epoch: 1\n",
      "2021-08-04 11:25:41,189 - ignite.engine.engine.SupervisedEvaluator - INFO - Epoch[1] Complete. Time taken: 00:00:18\n",
      "2021-08-04 11:25:41,189 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run complete. Time taken: 00:00:18\n",
      "2021-08-04 11:25:41,223 - medl.apps.mmar_conf - INFO - Total Evaluation Time 18.025229454040527\n"
     ]
    }
   ],
   "source": [
    "! $MMAR_ROOT/commands/validate.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "You could also run `validate_ckpt.sh` which loads the model from the checkpoint instead of the ts file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2Jrunning cmd /claraDevDay/GettingStarted//commands/validate_ckpt.sh\n",
      "PYTHONPATH is :/opt/nvidia/medical:/opt/nvidia:/opt/nvidia:/claraDevDay/GettingStarted/commands/../custom\n",
      "MMAR_ROOT set to /claraDevDay/GettingStarted/commands/..\n",
      "------------------------------------\n",
      "2021-08-04 11:25:46,969 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmpp7brj0hi\n",
      "2021-08-04 11:25:46,970 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmpp7brj0hi/_remote_module_non_sriptable.py\n",
      "loaded model config from checkpoint: /claraDevDay/GettingStarted/commands/../models/config_train_Unet/model.pt\n",
      "========== Validate Config Result ===========\n",
      "Use GPU:  True\n",
      "Multi GPU:  False\n",
      "Automatic Mixed Precision:  Enabled\n",
      "Determinism Evaluation:  Disabled\n",
      "cuDNN BenchMark:  False\n",
      "CUDA Matmul Allow TF32:  True\n",
      "cuDNN Allow TF32:  True\n",
      "Model:  <class 'monai.networks.nets.unet.UNet'>\n",
      "Dataset:  <class 'monai.data.dataset.Dataset'>\n",
      "DataLoader:  <class 'monai.data.dataloader.DataLoader'>\n",
      "Validate Transform #1: <class 'monai.transforms.io.dictionary.LoadImaged'>\n",
      "Validate Transform #2: <class 'monai.transforms.utility.dictionary.EnsureChannelFirstd'>\n",
      "Validate Transform #3: <class 'monai.transforms.spatial.dictionary.Spacingd'>\n",
      "Validate Transform #4: <class 'monai.transforms.intensity.dictionary.ScaleIntensityRanged'>\n",
      "Validate Transform #5: <class 'monai.transforms.croppad.dictionary.CropForegroundd'>\n",
      "Validate Transform #6: <class 'monai.transforms.utility.dictionary.ToTensord'>\n",
      "Validate Handler #1: <class 'monai.handlers.checkpoint_loader.CheckpointLoader'>\n",
      "Validate Handler #2: <class 'monai.handlers.stats_handler.StatsHandler'>\n",
      "Validate Handler #3: <class 'monai.handlers.segmentation_saver.SegmentationSaver'>\n",
      "Validate Handler #4: <class 'monai.handlers.metrics_saver.MetricsSaver'>\n",
      "Validate Post Transforms #1: <class 'monai.transforms.post.dictionary.Activationsd'>\n",
      "Validate Post Transforms #2: <class 'monai.transforms.post.dictionary.AsDiscreted'>\n",
      "Validate Inferer:  <class 'monai.inferers.inferer.SlidingWindowInferer'>\n",
      "Validate Key Metric:  <class 'monai.handlers.mean_dice.MeanDice'>\n",
      "Validate Additional Metric #val_acc: <class 'ignite.metrics.accuracy.Accuracy'>\n",
      "========== End of Validate Config Result ===========\n",
      "2021-08-04 11:25:50,293 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run resuming from iteration 0, epoch 0 until 1 epochs\n",
      "2021-08-04 11:25:50,313 - ignite.engine.engine.SupervisedEvaluator - INFO - Restored all variables from /claraDevDay/GettingStarted/commands/../models/config_train_Unet/model.pt\n",
      "file written: /claraDevDay/GettingStarted/eval/spleen_8/spleen_8_seg.nii.gz.\n",
      "2021-08-04 11:26:01,695 - ignite.engine.engine.SupervisedEvaluator - INFO - saved all the model outputs into files.\n",
      "file written: /claraDevDay/GettingStarted/eval/spleen_8/spleen_8_seg.nii.gz.\n",
      "2021-08-04 11:26:03,760 - ignite.engine.engine.SupervisedEvaluator - INFO - saved all the model outputs into files.\n",
      "file written: /claraDevDay/GettingStarted/eval/spleen_8/spleen_8_seg.nii.gz.\n",
      "2021-08-04 11:26:05,840 - ignite.engine.engine.SupervisedEvaluator - INFO - saved all the model outputs into files.\n",
      "file written: /claraDevDay/GettingStarted/eval/spleen_8/spleen_8_seg.nii.gz.\n",
      "2021-08-04 11:26:07,900 - ignite.engine.engine.SupervisedEvaluator - INFO - saved all the model outputs into files.\n",
      "2021-08-04 11:26:07,902 - ignite.engine.engine.SupervisedEvaluator - INFO - Got new best metric of val_mean_dice: 0.06937698274850845\n",
      "2021-08-04 11:26:07,902 - ignite.engine.engine.SupervisedEvaluator - INFO - Epoch[1] Metrics -- val_acc: 0.4644 val_mean_dice: 0.0694 \n",
      "2021-08-04 11:26:07,902 - ignite.engine.engine.SupervisedEvaluator - INFO - Key metric: val_mean_dice best value: 0.06937698274850845 at epoch: 1\n",
      "2021-08-04 11:26:07,904 - ignite.engine.engine.SupervisedEvaluator - INFO - Epoch[1] Complete. Time taken: 00:00:18\n",
      "2021-08-04 11:26:07,904 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run complete. Time taken: 00:00:18\n",
      "2021-08-04 11:26:07,937 - medl.apps.mmar_conf - INFO - Total Evaluation Time 17.644204139709473\n"
     ]
    }
   ],
   "source": [
    "! $MMAR_ROOT/commands/validate_ckpt.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 6.2 Validate with multiple GPUs \n",
    "You can also leverage multi-GPUs for validation using `validate_multi_gpu.sh` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2Jrunning cmd /claraDevDay/GettingStarted//commands/validate_multi_gpu.sh\n",
      "PYTHONPATH is :/opt/nvidia/medical:/opt/nvidia:/opt/nvidia:/claraDevDay/GettingStarted/commands/../custom\n",
      "MMAR_ROOT set to /claraDevDay/GettingStarted/commands/..\n",
      "------------------------------------\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "2021-08-04 11:26:14,229 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmp8vsu52wr\n",
      "2021-08-04 11:26:14,229 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmp6rb37f7h\n",
      "2021-08-04 11:26:14,230 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmp8vsu52wr/_remote_module_non_sriptable.py\n",
      "2021-08-04 11:26:14,230 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmp6rb37f7h/_remote_module_non_sriptable.py\n",
      "2021-08-04 11:26:15,403 - root - INFO - Added key: store_based_barrier_key:1 to store for rank: 1\n",
      "2021-08-04 11:26:15,407 - root - INFO - Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "Error processing config /claraDevDay/GettingStarted/commands/../config/config_validation.json: CUDA error: invalid device ordinal\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"apps/evaluate.py\", line 31, in <module>\n",
      "  File \"apps/evaluate.py\", line 23, in main\n",
      "  File \"apps/mmar_conf.py\", line 60, in evaluate_mmar\n",
      "  File \"<nvflare-0.1.4>/dlmed/utils/wfconf.py\", line 172, in configure\n",
      "  File \"<nvflare-0.1.4>/dlmed/utils/wfconf.py\", line 167, in configure\n",
      "  File \"<nvflare-0.1.4>/dlmed/utils/wfconf.py\", line 163, in _do_configure\n",
      "  File \"apps/eval_configer.py\", line 237, in finalize_config\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 257, in set_device\n",
      "    torch._C._cuda_setDevice(device)\n",
      "RuntimeError: CUDA error: invalid device ordinal\n",
      "Killing subprocess 1231\n",
      "Killing subprocess 1232\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py\", line 340, in <module>\n",
      "    main()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py\", line 326, in main\n",
      "    sigkill_handler(signal.SIGTERM, None)  # not coming back\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py\", line 301, in sigkill_handler\n",
      "    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', '-m', 'medl.apps.evaluate', '--local_rank=1', '-m', '/claraDevDay/GettingStarted/commands/..', '-c', 'config/config_validation.json', '-e', 'config/environment.json', '--set', 'MMAR_TORCHSCRIPT=models/config_train_Unet/model.ts', 'print_conf=True', 'multi_gpu=True', 'dont_load_ts_model=False', 'dont_load_ckpt_model=True']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!$MMAR_ROOT/commands/validate_multi_gpu.sh "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Similarly you could also run `validate_multi_gpu_ckpt.sh` which loads the model from the checkpoint instead of the ts file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2Jrunning cmd /claraDevDay/GettingStarted//commands/validate_multi_gpu_ckpt.sh\n",
      "PYTHONPATH is :/opt/nvidia/medical:/opt/nvidia:/opt/nvidia:/claraDevDay/GettingStarted/commands/../custom\n",
      "MMAR_ROOT set to /claraDevDay/GettingStarted/commands/..\n",
      "------------------------------------\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "2021-08-04 11:26:21,682 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmpm6cvou1x\n",
      "2021-08-04 11:26:21,683 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmpm6cvou1x/_remote_module_non_sriptable.py\n",
      "2021-08-04 11:26:21,693 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmp08doaku3\n",
      "2021-08-04 11:26:21,693 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmp08doaku3/_remote_module_non_sriptable.py\n",
      "2021-08-04 11:26:23,847 - root - INFO - Added key: store_based_barrier_key:1 to store for rank: 1\n",
      "2021-08-04 11:26:23,854 - root - INFO - Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "Error processing config /claraDevDay/GettingStarted/commands/../config/config_validation.json: CUDA error: invalid device ordinal\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"apps/evaluate.py\", line 31, in <module>\n",
      "  File \"apps/evaluate.py\", line 23, in main\n",
      "  File \"apps/mmar_conf.py\", line 60, in evaluate_mmar\n",
      "  File \"<nvflare-0.1.4>/dlmed/utils/wfconf.py\", line 172, in configure\n",
      "  File \"<nvflare-0.1.4>/dlmed/utils/wfconf.py\", line 167, in configure\n",
      "  File \"<nvflare-0.1.4>/dlmed/utils/wfconf.py\", line 163, in _do_configure\n",
      "  File \"apps/eval_configer.py\", line 237, in finalize_config\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 257, in set_device\n",
      "    torch._C._cuda_setDevice(device)\n",
      "RuntimeError: CUDA error: invalid device ordinal\n",
      "Killing subprocess 1269\n",
      "Killing subprocess 1270\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py\", line 340, in <module>\n",
      "    main()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py\", line 326, in main\n",
      "    sigkill_handler(signal.SIGTERM, None)  # not coming back\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py\", line 301, in sigkill_handler\n",
      "    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', '-m', 'medl.apps.evaluate', '--local_rank=1', '-m', '/claraDevDay/GettingStarted/commands/..', '-c', 'config/config_validation.json', '-e', 'config/environment.json', '--set', 'MMAR_CKPT=models/config_train_Unet/model.pt', 'print_conf=True', 'multi_gpu=True', 'dont_load_ts_model=True', 'dont_load_ckpt_model=False']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "! $MMAR_ROOT/commands/validate_multi_gpu_ckpt.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 6.3 Check Validation results \n",
    "Now lets see results in the folder by running cells below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24\n",
      "drwxrwxr-x  3 1000 1000 4096 Aug  4 11:25 .\n",
      "drwxrwxr-x 11 1000 1000 4096 Aug  4 11:26 ..\n",
      "-rw-rw-r--  1 1000 1000    0 Aug  4 08:28 .gitignore\n",
      "-rw-r--r--  1 root root   62 Aug  4 11:26 metrics.csv\n",
      "drwxr-xr-x  2 root root 4096 Aug  4 11:25 spleen_8\n",
      "-rw-r--r--  1 root root  325 Aug  4 11:26 val_mean_dice_raw.csv\n",
      "-rw-r--r--  1 root root  136 Aug  4 11:26 val_mean_dice_summary.csv\n",
      "---------------------------------------\n",
      "Display content of  metrics.csv\n",
      "val_mean_dice\t0.06937698274850845\n",
      "val_acc\t0.46444148176841094\n",
      "---------------------------------------\n",
      "Display content of  val_mean_dice_raw.csv\n",
      "filename\tclass0\tmean\n",
      "/claraDevDay/Data/sampleData/imagesTr/spleen_8.nii.gz\t0.06937719\t0.06937719\n",
      "/claraDevDay/Data/sampleData/imagesTr/spleen_8.nii.gz\t0.06937674\t0.06937674\n",
      "/claraDevDay/Data/sampleData/imagesTr/spleen_8.nii.gz\t0.06937729\t0.06937729\n",
      "/claraDevDay/Data/sampleData/imagesTr/spleen_8.nii.gz\t0.06937672\t0.06937672\n",
      "---------------------------------------\n",
      "Display content of  val_mean_dice_summary.csv\n",
      "class\tmean\tmedian\tmax\tmin\t90percent\tstd\n",
      "class0\t0.0694\t0.0694\t0.0694\t0.0694\t0.0694\t0.0000\n",
      "mean\t0.0694\t0.0694\t0.0694\t0.0694\t0.0694\t0.0000\n"
     ]
    }
   ],
   "source": [
    "!ls -la $MMAR_ROOT/eval\n",
    "for fName in [\"metrics.csv\",\"val_mean_dice_raw.csv\",\"val_mean_dice_summary.csv\"]:\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"Display content of \",fName)\n",
    "    ! cat $MMAR_ROOT/eval/$fName\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# 7. Inference  \n",
    "\n",
    "To run inference on validation dataset or test dataset you should run `infer.sh`. \n",
    "This will run prediction on the validation dataset and place it in the `MMAR_EVAL_OUTPUT_PATH` as configured in the \n",
    "[environment.json](config/environment.json) file (default is eval folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2Jrunning cmd /claraDevDay/GettingStarted//commands/infer.sh\n",
      "PYTHONPATH is :/opt/nvidia/medical:/opt/nvidia:/opt/nvidia:/claraDevDay/GettingStarted/commands/../custom\n",
      "MMAR_ROOT set to /claraDevDay/GettingStarted/commands/..\n",
      "------------------------------------\n",
      "2021-08-04 11:26:58,542 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmp7c8v5tcz\n",
      "2021-08-04 11:26:58,543 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmp7c8v5tcz/_remote_module_non_sriptable.py\n",
      "loaded TorchScript model from path: /claraDevDay/GettingStarted/commands/../models/config_train_Unet/model.ts\n",
      "========== Validate Config Result ===========\n",
      "Use GPU:  True\n",
      "Multi GPU:  False\n",
      "Automatic Mixed Precision:  Enabled\n",
      "Determinism Evaluation:  Disabled\n",
      "cuDNN BenchMark:  False\n",
      "CUDA Matmul Allow TF32:  True\n",
      "cuDNN Allow TF32:  True\n",
      "Model:  <class 'torch.jit._script.RecursiveScriptModule'>\n",
      "Dataset:  <class 'monai.data.dataset.Dataset'>\n",
      "DataLoader:  <class 'monai.data.dataloader.DataLoader'>\n",
      "Validate Transform #1: <class 'monai.transforms.io.dictionary.LoadImaged'>\n",
      "Validate Transform #2: <class 'monai.transforms.utility.dictionary.EnsureChannelFirstd'>\n",
      "Validate Transform #3: <class 'monai.transforms.intensity.dictionary.ScaleIntensityRanged'>\n",
      "Validate Transform #4: <class 'monai.transforms.croppad.dictionary.CropForegroundd'>\n",
      "Validate Transform #5: <class 'monai.transforms.utility.dictionary.ToTensord'>\n",
      "Validate Handler #1: <class 'monai.handlers.stats_handler.StatsHandler'>\n",
      "Validate Handler #2: <class 'monai.handlers.segmentation_saver.SegmentationSaver'>\n",
      "Validate Post Transforms #1: <class 'monai.transforms.post.dictionary.Activationsd'>\n",
      "Validate Post Transforms #2: <class 'monai.transforms.post.dictionary.AsDiscreted'>\n",
      "Validate Inferer:  <class 'monai.inferers.inferer.SlidingWindowInferer'>\n",
      "========== End of Validate Config Result ===========\n",
      "2021-08-04 11:27:01,977 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run resuming from iteration 0, epoch 0 until 1 epochs\n",
      "file written: /claraDevDay/GettingStarted/eval/spleen_8/spleen_8_seg.nii.gz.\n",
      "2021-08-04 11:27:04,525 - ignite.engine.engine.SupervisedEvaluator - INFO - saved all the model outputs into files.\n",
      "file written: /claraDevDay/GettingStarted/eval/spleen_8/spleen_8_seg.nii.gz.\n",
      "2021-08-04 11:27:05,513 - ignite.engine.engine.SupervisedEvaluator - INFO - saved all the model outputs into files.\n",
      "2021-08-04 11:27:05,513 - ignite.engine.engine.SupervisedEvaluator - INFO - Epoch[1] Complete. Time taken: 00:00:03\n",
      "2021-08-04 11:27:05,513 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run complete. Time taken: 00:00:04\n",
      "2021-08-04 11:27:05,545 - medl.apps.mmar_conf - INFO - Total Evaluation Time 3.5672426223754883\n"
     ]
    }
   ],
   "source": [
    "! $MMAR_ROOT/commands/infer.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Now lets see results in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24\n",
      "drwxrwxr-x  3 1000 1000 4096 Aug  4 11:25 .\n",
      "drwxrwxr-x 11 1000 1000 4096 Aug  4 11:26 ..\n",
      "-rw-rw-r--  1 1000 1000    0 Aug  4 08:28 .gitignore\n",
      "-rw-r--r--  1 root root   62 Aug  4 11:26 metrics.csv\n",
      "drwxr-xr-x  2 root root 4096 Aug  4 11:25 spleen_8\n",
      "-rw-r--r--  1 root root  325 Aug  4 11:26 val_mean_dice_raw.csv\n",
      "-rw-r--r--  1 root root  136 Aug  4 11:26 val_mean_dice_summary.csv\n"
     ]
    }
   ],
   "source": [
    "! ls -la $MMAR_ROOT/eval/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3204\n",
      "drwxr-xr-x 2 root root    4096 Aug  4 11:25 .\n",
      "drwxrwxr-x 3 1000 1000    4096 Aug  4 11:25 ..\n",
      "-rw-r--r-- 1 root root 3269759 Aug  4 11:27 spleen_8_seg.nii.gz\n"
     ]
    }
   ],
   "source": [
    "! ls -la $MMAR_ROOT/eval/spleen_8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# 8.Multi-GPU Training\n",
    "Clara train aims to simplify scaling and utilizing all available GPUs. \n",
    "Using the same config we already used for train we can simply invoke `train_multi_gpu.sh` to train on multiple gpus. \n",
    "Main difference between the `train.sh` and `train_multi_gpu.sh` is changing some parameters\n",
    "\n",
    "train.sh | train_multi_gpu.sh  \n",
    " --- | --- \n",
    "python3 -u -m medl.apps.train \\\\<br>-m MMAR_ROOT \\\\<br>-c CONFIG_FILE \\\\<br>-e ENVIRONMENT_FILE \\\\<br>--write_train_stats \\\\<br>--set \\\\<br> print_conf=True | python -m torch.distributed.launch\\\\<br> --nproc_per_node=2 --nnodes=1 --node_rank=0 \\\\<br> --master_addr=\"localhost\" --master_port=1234 \\\\<br>-m medl.apps.train \\\\<br>-m MMAR_ROOT \\\\<br>-c CONFIG_FILE \\\\<br>-e ENVIRONMENT_FILE \\\\<br> --write_train_stats \\\\<br> --set \\\\<br> print_conf=True \\\\<br> multi_gpu=True \\\\<br> learning_rate= 2e-4\n",
    " \n",
    "Lets examine `train_multi_gpu.sh` script by running cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "printFile(MMAR_ROOT+\"/commands/train_multi_gpu.sh\",0,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Lets give it a try and run cell below to train on 2 GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! $MMAR_ROOT/commands/train_multi_gpu.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "# 9. Training Vs FineTune\n",
    "`train.sh` and `finetune.sh` are identical and use the same config file. \n",
    "The only difference is that `finetune.sh` enables the load of check point using the `disabled` as shown below \n",
    "\n",
    "except they train using different configurations files. \n",
    "\n",
    "_Note_: The only difference between the two configs `config_train_Unet.json` and `config_finetune.json` \n",
    "is that `config_finetune.json` specifies a `ckpt` file in section below \n",
    "while `config_train_Unet.json` does not since it is training from scratch.\n",
    "```\n",
    "      {\n",
    "        \"name\": \"CheckpointLoader\",\n",
    "        \"args\": {\n",
    "          \"disabled\": \"{dont_load_ckpt_model}\",\n",
    "          \"load_path\": \"{MMAR_CKPT}\",\n",
    "          \"load_dict\": [\"model\"]\n",
    "        }\n",
    "      },\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# 10. Profiling\n",
    "Nvidia provides multiple tools for profiling your training in order to eliminate bottlenecks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 10.1 Profiling with DLprof \n",
    "DLprof is a simple tool that does the analysis in of regular training then display results in tensorboard.\n",
    "Moreover, it provides recommendations guiding user on how to improve performance \n",
    "\n",
    "Cell below uses DLprof tool. \n",
    "We will use same config as we used above expect it have `AMP=false` to see DLProf analysis  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "!$MMAR_ROOT/commands/debug_dlprof.sh config_train_Unet_NoAMP.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "You then need to run tensor board manually (Not through jupyterlab) using \n",
    "```\n",
    "cd /claraDevDay/GettingStarted/models/config_train_Unet_NoAMP_debug\n",
    "tensorboard --logdir ./dlprof --port 5000\n",
    "```\n",
    "Recall we mounted port 3031 to 5000 by default for AIAA in the `docker-compose.yml` file, \n",
    "we simply are using that mapping here for simplicity \n",
    "now if you navigate to `<yourip:3031>` you should see DlProf tool as below. \n",
    "This analysis shows you the GPUs you have along improvements that you can do to train faster. \n",
    "For example this run shows multiple operations that would be accelerated from AMP.\n",
    "To test this you can run cell below with AMP enabled in the configuration \n",
    "\n",
    "<br><img src=\"screenShots/Dlprof.png\" alt=\"Drawing\" style=\"height: 400px;\"/><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 10.2 Profile your model with Nsight System\n",
    "Nsight System is more advanced\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "In order to train faster you would need to analyze your training loop and check for bottlenecks.\n",
    "1. Download Nisght Systems locally on your machine from https://developer.nvidia.com/nsight-systems \n",
    "2. Open Nsight System locally (out side the docker)\n",
    "3. Load up files from <local path>/GettingStarted/models/config_train_Unet_NoAMP_debug\n",
    "you should see image analysis as below \n",
    "<br><img src=\"screenShots/Nsight1FromDlprof.png\" alt=\"Drawing\" style=\"height: 400px;\"/><br>\n",
    "\n",
    "# Next:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### 1. Load model into AIAA\n",
    "We will show here how you can quickly load up the model we trained above into AIAA. \n",
    "First, you should run [AIAA Notebook](../AIAA/AIAA.ipynb) to start the server.\n",
    "Section 3.1 in the AIAA notebook shows how to load trained model into AIAA server. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### 2. Bring your own Components\n",
    "In order to fully take advantage of clara train SDK you should write your own components. \n",
    "Please go to [BYOC notebook](BYOC.ipynb) for examples  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Exercise:\n",
    "Now that you are familiar with clara train, you can try to: \n",
    "1. Explore different options of clara train by changing / creating a new config file and running training: \n",
    "    1. Model architecture: Ahnet, Unet, Segresnet \n",
    "    2. Losses\n",
    "    3. Transformation \n",
    "\n",
    "Hint: you for training segresnet you can use the configuration `config_train_segresnet.json` that only changed the network section.\n",
    "you can train by running cell below     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!$MMAR_ROOT/commands/train_W_Config.sh config_train_segresnet.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. Train on real spleen data for this you should:\n",
    "    1. Download spleen dataset by running the [download](../Data/DownloadDecathlonDataSet.ipynb) Notebook\n",
    "    2. Switch the dataset file in the [environment.json](config/environment.json)\n",
    "    3. rerun the `train.sh`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "3. Experiment with multi-GPU training by changing number of gpus to train on from 2 to 3 or 4. \n",
    "You should edit [train_multi_gpu.sh](commands/train_multi_gpu.sh) then rerun the script \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": "<!--- SPDX-License-Identifier: Apache-2.0 -->\n"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
